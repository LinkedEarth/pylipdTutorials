{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4bc9c4-efaf-4fef-bd9f-b87a4b611c5c",
   "metadata": {},
   "source": [
    "# Filtering through queries\n",
    "\n",
    "## Authors\n",
    "\n",
    "[Deborah Khider](https://orcid.org/0000-0001-7501-8430)\n",
    "\n",
    "## Preamble\n",
    "\n",
    "`PyLiPD` is a Python package that allows you to read, manipulate, and write [LiPD](https://doi.org/10.5194/cp-12-1093-2016) formatted datasets. In this tutorial, we will demonstrate how to use pre-defined filtering capabilities through APIs. \n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Note:</b> This capabilities are under heavy development. If you are interested in other filtering capabilities to help with your science, please <a href='https://github.com/LinkedEarth/pylipd/issues'>open an issue</a>.\n",
    "</div>\n",
    "\n",
    "### Goals\n",
    "\n",
    "* Use existing APIs to filter datasets according to archive types, location and variable names.\n",
    "* Understand the concept of a `LiPDSeries` object and how it differs from `LiPD` object.\n",
    "\n",
    "Reading Time: 5 minutes\n",
    "\n",
    "### Keywords\n",
    "\n",
    "LiPD\n",
    "\n",
    "### Pre-requisites\n",
    "\n",
    "* This tutorial assumes basic knowledge of Python and Pandas. If you are not familiar with this coding language and this particular library, check out this tutorial: http://linked.earth/ec_workshops_py/.\n",
    "* [Retrieving Information from LiPD files](L1_getting_information.md)\n",
    "\n",
    "### Relevant Packages\n",
    "\n",
    "pylipd\n",
    "\n",
    "## Data Description\n",
    "\n",
    "This notebook uses the following datasets, in LiPD format:\n",
    "\n",
    "- Euro2k database: PAGES2k Consortium (2017), A global multiproxy database for temperature reconstructions of the Common Era. Sci Data 4, 170088. doi:10.1038/sdata.2017.88\n",
    "\n",
    "## Demonstration\n",
    "\n",
    "### Filtering by the type of archive\n",
    "\n",
    "Let's start by importing our favorite package and load our datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21a893e-73d2-4709-ae55-ea5cb199564c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 16 LiPD files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 16/16 [00:00<00:00, 157.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pylipd.lipd import LiPD\n",
    "\n",
    "path = '../data/Pages2k/'\n",
    "\n",
    "D = LiPD()\n",
    "D.load_from_dir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51ef11a-3661-4b4c-89a0-a84469a28064",
   "metadata": {},
   "source": [
    "And let's get a list of available datasets so we can compare the results as we filter using various criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4795d91-85cf-4b24-902c-7b0f3725c3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ocn-RedSea.Felis.2000',\n",
       " 'Ant-WAIS-Divide.Severinghaus.2012',\n",
       " 'Asi-SourthAndMiddleUrals.Demezhko.2007',\n",
       " 'Ocn-AlboranSea436B.Nieto-Moreno.2013',\n",
       " 'Eur-SpannagelCave.Mangini.2005',\n",
       " 'Ocn-FeniDrift.Richter.2009',\n",
       " 'Eur-LakeSilvaplana.Trachsel.2010',\n",
       " 'Ocn-PedradeLume-CapeVerdeIslands.Moses.2006',\n",
       " 'Ocn-SinaiPeninsula_RedSea.Moustafa.2000',\n",
       " 'Eur-NorthernSpain.Martin-Chivelet.2011',\n",
       " 'Arc-Kongressvatnet.D_Andrea.2012',\n",
       " 'Eur-CoastofPortugal.Abrantes.2011',\n",
       " 'Eur-SpanishPyrenees.Dorado-Linan.2012',\n",
       " 'Eur-FinnishLakelands.Helama.2014',\n",
       " 'Eur-NorthernScandinavia.Esper.2012',\n",
       " 'Eur-Stockholm.Leijonhufvud.2009']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.get_all_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d25b81-3dcb-458c-b85d-ebda2c7de751",
   "metadata": {},
   "source": [
    "Now let's look at the available types of archives for which we can filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06621bc9-b289-4954-b48b-4cd8791fcd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coral',\n",
       " 'Borehole',\n",
       " 'Marine sediment',\n",
       " 'Speleothem',\n",
       " 'Lake sediment',\n",
       " 'Wood',\n",
       " 'Documents']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.get_all_archiveTypes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f029fada-3fa6-4e69-bfdf-66e0d045ef79",
   "metadata": {},
   "source": [
    "Let's first filter for speleothem records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ee53c0-e992-4623-895a-20454a57a09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eur-NorthernSpain.Martin-Chivelet.2011', 'Eur-SpannagelCave.Mangini.2005']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_speleothem = D.filter_by_archive_type('speleothem')\n",
    "\n",
    "D_speleothem.get_all_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6406943e-d454-4a76-8de5-408e82077d5a",
   "metadata": {},
   "source": [
    "The function uses [regular expressions](https://learn.microsoft.com/en-us/dotnet/standard/base-types/regular-expression-language-quick-reference) to do partial matches. Therefore, you can look for all the datasets based on marine sediments using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbea64a8-094d-4b2a-8c01-a60a75522f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ocn-FeniDrift.Richter.2009',\n",
       " 'Eur-CoastofPortugal.Abrantes.2011',\n",
       " 'Ocn-AlboranSea436B.Nieto-Moreno.2013']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_marine = D.filter_by_archive_type('marine')\n",
    "\n",
    "D_marine.get_all_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63e7b27-4c0f-4443-9f94-b3311f6a4656",
   "metadata": {},
   "source": [
    "However, looking for `sediment` will return records based on both marine and lake sediments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be13599-cf87-4027-b12d-ad58e4e4791d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eur-LakeSilvaplana.Trachsel.2010',\n",
       " 'Ocn-FeniDrift.Richter.2009',\n",
       " 'Eur-CoastofPortugal.Abrantes.2011',\n",
       " 'Arc-Kongressvatnet.D_Andrea.2012',\n",
       " 'Ocn-AlboranSea436B.Nieto-Moreno.2013']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_sediment = D.filter_by_archive_type('sediment')\n",
    "\n",
    "D_sediment.get_all_dataset_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "129ae5fa-e124-464a-8290-73dadcb836c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eur-NorthernSpain.Martin-Chivelet.2011',\n",
       " 'Ocn-AlboranSea436B.Nieto-Moreno.2013',\n",
       " 'Ocn-FeniDrift.Richter.2009',\n",
       " 'Eur-CoastofPortugal.Abrantes.2011',\n",
       " 'Eur-SpannagelCave.Mangini.2005']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_marinespeleo = D.filter_by_archive_type('(marine|speleothem)')\n",
    "\n",
    "D_marinespeleo.get_all_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a941f7-94df-4a10-a6bc-91d23fc2897f",
   "metadata": {},
   "source": [
    "If you are not comfortable with regular expression and constructing patterns as we have done above, you can always merge two `LiPD` objects as we demonstrated [previously](L0_loading_lipd_datasets.ipynb). Therefore, the filtering above can also be achieved by combining our previous objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30e20778-66f0-4b76-91e7-2d7c6fb32e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ocn-AlboranSea436B.Nieto-Moreno.2013',\n",
       " 'Ocn-FeniDrift.Richter.2009',\n",
       " 'Eur-CoastofPortugal.Abrantes.2011',\n",
       " 'Eur-NorthernSpain.Martin-Chivelet.2011',\n",
       " 'Eur-SpannagelCave.Mangini.2005']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_merged = D_marine.merge(D_speleothem)\n",
    "\n",
    "D_merged.get_all_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a138f8b0-1092-469c-a3b1-cda2d47a0788",
   "metadata": {},
   "source": [
    "### Filtering by location\n",
    "\n",
    "Let's filter using a [bounding box](https://pylipd.readthedocs.io/en/latest/source/pylipd.html#pylipd.lipd.LiPD.filter_by_geo_bbox) between 40-70N and 0-90E:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddea410f-b228-475c-9a0b-7741f84fb7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Asi-SourthAndMiddleUrals.Demezhko.2007',\n",
       " 'Eur-LakeSilvaplana.Trachsel.2010',\n",
       " 'Eur-FinnishLakelands.Helama.2014',\n",
       " 'Eur-NorthernScandinavia.Esper.2012',\n",
       " 'Eur-SpannagelCave.Mangini.2005',\n",
       " 'Eur-SpanishPyrenees.Dorado-Linan.2012',\n",
       " 'Eur-Stockholm.Leijonhufvud.2009']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_geo = D.filter_by_geo_bbox(lonMin=0, latMin=40, lonMax=90, latMax=70)\n",
    "\n",
    "D_geo.get_all_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eefa0b-c356-47d0-b546-c5bf5d1dc91e",
   "metadata": {},
   "source": [
    "Because `PyLiPD` uses object-oriented programming, we can take advantage of method cascading to create a series of filters. For instance, let's assume that we want all the datasets between 40-70N and 0-90E that are trees. One can write an additional query on top of the location query that we just performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "627ba50d-aa6f-4933-88fc-521867d0ba0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eur-NorthernScandinavia.Esper.2012',\n",
       " 'Eur-FinnishLakelands.Helama.2014',\n",
       " 'Eur-SpanishPyrenees.Dorado-Linan.2012']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_geotree = D_geo.filter_by_archive_type('wood')\n",
    "\n",
    "D_geotree.get_all_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f21606-bdbd-4f27-9fd5-40a304b76076",
   "metadata": {},
   "source": [
    "Using method cascading, you can write this in a single query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86226a3-802e-4042-9b93-202c6ac8e963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Eur-NorthernScandinavia.Esper.2012',\n",
       " 'Eur-FinnishLakelands.Helama.2014',\n",
       " 'Eur-SpanishPyrenees.Dorado-Linan.2012']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_filt = D.filter_by_geo_bbox(lonMin=0, latMin=40, lonMax=90, latMax=70).filter_by_archive_type('wood')\n",
    "\n",
    "D_filt.get_all_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ea2fe-8bd1-4c59-91d6-f8de03557f6b",
   "metadata": {},
   "source": [
    "### Filtering by variable names\n",
    "\n",
    "Most of the time, we are interested in working with specific variables in a LiPD file. To use filtering capabilities, this requires expanding the `LiPD` object into a `LiPDSeries` object, which contains individual variables. You can do so by using the following function, applied on the filtered database of tree records from high northern latitudes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cae7cda-6099-4e68-bdea-086651e5fc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LiPD Series...\n",
      "- Extracting dataset subgraphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 269.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Extracting variable subgraphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 17.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ts = D_filt.to_lipd_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9f6c4d-6d77-4dbd-a6fb-085d878aea19",
   "metadata": {},
   "source": [
    "Let's have a look at what we have by placing essential metadata into a Pandas DataFrame. This function is the equivalent to `LiPD.get_timeseries_essentials` with slight differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de63aa23-99fb-43d2-8cd4-8d11198a45b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataSetName</th>\n",
       "      <th>archiveType</th>\n",
       "      <th>name</th>\n",
       "      <th>TSID</th>\n",
       "      <th>values</th>\n",
       "      <th>units</th>\n",
       "      <th>proxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eur-SpanishPyrenees.Dorado-Linan.2012</td>\n",
       "      <td>tree</td>\n",
       "      <td>trsgi</td>\n",
       "      <td>Eur_020</td>\n",
       "      <td>[-1.612, -0.703, -0.36, -0.767, -0.601, -0.733...</td>\n",
       "      <td>None</td>\n",
       "      <td>TRW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eur-SpanishPyrenees.Dorado-Linan.2012</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYT2K8MIA3N</td>\n",
       "      <td>[1260.0, 1261.0, 1262.0, 1263.0, 1264.0, 1265....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eur-FinnishLakelands.Helama.2014</td>\n",
       "      <td>tree</td>\n",
       "      <td>temperature</td>\n",
       "      <td>Eur_005</td>\n",
       "      <td>[14.603, 14.643, 12.074, 13.898, 13.671, 13.41...</td>\n",
       "      <td>degC</td>\n",
       "      <td>MXD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eur-FinnishLakelands.Helama.2014</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYTUSB62S0A</td>\n",
       "      <td>[2000.0, 1999.0, 1998.0, 1997.0, 1996.0, 1995....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eur-NorthernScandinavia.Esper.2012</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYTECO66XAD</td>\n",
       "      <td>[-138.0, -137.0, -136.0, -135.0, -134.0, -133....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dataSetName archiveType         name   \n",
       "0  Eur-SpanishPyrenees.Dorado-Linan.2012        tree        trsgi  \\\n",
       "1  Eur-SpanishPyrenees.Dorado-Linan.2012        tree         year   \n",
       "2       Eur-FinnishLakelands.Helama.2014        tree  temperature   \n",
       "3       Eur-FinnishLakelands.Helama.2014        tree         year   \n",
       "4     Eur-NorthernScandinavia.Esper.2012        tree         year   \n",
       "\n",
       "          TSID                                             values units proxy  \n",
       "0      Eur_020  [-1.612, -0.703, -0.36, -0.767, -0.601, -0.733...  None   TRW  \n",
       "1  PYT2K8MIA3N  [1260.0, 1261.0, 1262.0, 1263.0, 1264.0, 1265....    AD  None  \n",
       "2      Eur_005  [14.603, 14.643, 12.074, 13.898, 13.671, 13.41...  degC   MXD  \n",
       "3  PYTUSB62S0A  [2000.0, 1999.0, 1998.0, 1997.0, 1996.0, 1995....    AD  None  \n",
       "4  PYTECO66XAD  [-138.0, -137.0, -136.0, -135.0, -134.0, -133....    AD  None  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ts.get_timeseries_essentials()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f61e6-29b5-4852-ad1c-e2df74ac5b28",
   "metadata": {},
   "source": [
    "As you can see, the DataFrame contains much of the same information, except for location. This is because that information is stored at the Dataset level in LiPD and is, therefore, attached to the `LiPD` object. But you can merge the data using [Pandas' capabilities](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html). First, let's get the location information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9ab7663-97f5-4ece-9b2b-1233fb5b8c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataSetName</th>\n",
       "      <th>geo_meanLat</th>\n",
       "      <th>geo_meanLon</th>\n",
       "      <th>geo_meanElev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eur-SpanishPyrenees.Dorado-Linan.2012</td>\n",
       "      <td>42.5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eur-NorthernScandinavia.Esper.2012</td>\n",
       "      <td>68.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eur-FinnishLakelands.Helama.2014</td>\n",
       "      <td>62.0</td>\n",
       "      <td>28.325</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dataSetName  geo_meanLat  geo_meanLon   \n",
       "0  Eur-SpanishPyrenees.Dorado-Linan.2012         42.5        1.000  \\\n",
       "1     Eur-NorthernScandinavia.Esper.2012         68.0       25.000   \n",
       "2       Eur-FinnishLakelands.Helama.2014         62.0       28.325   \n",
       "\n",
       "   geo_meanElev  \n",
       "0        1200.0  \n",
       "1         300.0  \n",
       "2         130.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loc = D_filt.get_all_locations()\n",
    "\n",
    "df_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99af25fd-c7a2-48be-b602-7c308535cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129f62da-306a-4aad-9b0f-751f911dd726",
   "metadata": {},
   "source": [
    "We can use the [`.merge`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) functionality in Pandas to achieve our goal. This functionality is very similar to `join` in SQL. The main arguments are `how` which defines how the join is achieved and `on` which specifies the column:\n",
    "\n",
    "`how`: {‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘inner’\n",
    "\n",
    "* left: use only keys from left frame, similar to a SQL left outer join; preserve key order.\n",
    "* right: use only keys from right frame, similar to a SQL right outer join; preserve key order.\n",
    "* outer: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically.\n",
    "* inner: use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys.\n",
    "* cross: creates the cartesian product from both frames, preserves the order of the left keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8c6579c-112a-4a97-9a1b-01198685ac38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataSetName</th>\n",
       "      <th>archiveType</th>\n",
       "      <th>name</th>\n",
       "      <th>TSID</th>\n",
       "      <th>values</th>\n",
       "      <th>units</th>\n",
       "      <th>proxy</th>\n",
       "      <th>geo_meanLat</th>\n",
       "      <th>geo_meanLon</th>\n",
       "      <th>geo_meanElev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eur-SpanishPyrenees.Dorado-Linan.2012</td>\n",
       "      <td>tree</td>\n",
       "      <td>trsgi</td>\n",
       "      <td>Eur_020</td>\n",
       "      <td>[-1.612, -0.703, -0.36, -0.767, -0.601, -0.733...</td>\n",
       "      <td>None</td>\n",
       "      <td>TRW</td>\n",
       "      <td>42.5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eur-SpanishPyrenees.Dorado-Linan.2012</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYT2K8MIA3N</td>\n",
       "      <td>[1260.0, 1261.0, 1262.0, 1263.0, 1264.0, 1265....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "      <td>42.5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eur-FinnishLakelands.Helama.2014</td>\n",
       "      <td>tree</td>\n",
       "      <td>temperature</td>\n",
       "      <td>Eur_005</td>\n",
       "      <td>[14.603, 14.643, 12.074, 13.898, 13.671, 13.41...</td>\n",
       "      <td>degC</td>\n",
       "      <td>MXD</td>\n",
       "      <td>62.0</td>\n",
       "      <td>28.325</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eur-FinnishLakelands.Helama.2014</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYTUSB62S0A</td>\n",
       "      <td>[2000.0, 1999.0, 1998.0, 1997.0, 1996.0, 1995....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "      <td>62.0</td>\n",
       "      <td>28.325</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eur-NorthernScandinavia.Esper.2012</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYTECO66XAD</td>\n",
       "      <td>[-138.0, -137.0, -136.0, -135.0, -134.0, -133....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "      <td>68.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dataSetName archiveType         name   \n",
       "0  Eur-SpanishPyrenees.Dorado-Linan.2012        tree        trsgi  \\\n",
       "1  Eur-SpanishPyrenees.Dorado-Linan.2012        tree         year   \n",
       "2       Eur-FinnishLakelands.Helama.2014        tree  temperature   \n",
       "3       Eur-FinnishLakelands.Helama.2014        tree         year   \n",
       "4     Eur-NorthernScandinavia.Esper.2012        tree         year   \n",
       "\n",
       "          TSID                                             values units proxy   \n",
       "0      Eur_020  [-1.612, -0.703, -0.36, -0.767, -0.601, -0.733...  None   TRW  \\\n",
       "1  PYT2K8MIA3N  [1260.0, 1261.0, 1262.0, 1263.0, 1264.0, 1265....    AD  None   \n",
       "2      Eur_005  [14.603, 14.643, 12.074, 13.898, 13.671, 13.41...  degC   MXD   \n",
       "3  PYTUSB62S0A  [2000.0, 1999.0, 1998.0, 1997.0, 1996.0, 1995....    AD  None   \n",
       "4  PYTECO66XAD  [-138.0, -137.0, -136.0, -135.0, -134.0, -133....    AD  None   \n",
       "\n",
       "   geo_meanLat  geo_meanLon  geo_meanElev  \n",
       "0         42.5        1.000        1200.0  \n",
       "1         42.5        1.000        1200.0  \n",
       "2         62.0       28.325         130.0  \n",
       "3         62.0       28.325         130.0  \n",
       "4         68.0       25.000         300.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df.merge(df_loc,how='inner', on='dataSetName')\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb12f98-221a-48a7-ba60-3083262f19b7",
   "metadata": {},
   "source": [
    "The second difference is that the variables representing time are only present as rows, which means that time will need to be associated with the variables. To do so, you can use the filtering capabilities. First, let's filter for `temperature` and `trsgi`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7cae044-ce43-4ac5-9421-ac065d98ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataSetName</th>\n",
       "      <th>archiveType</th>\n",
       "      <th>name</th>\n",
       "      <th>TSID</th>\n",
       "      <th>values</th>\n",
       "      <th>units</th>\n",
       "      <th>proxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eur-SpanishPyrenees.Dorado-Linan.2012</td>\n",
       "      <td>tree</td>\n",
       "      <td>trsgi</td>\n",
       "      <td>Eur_020</td>\n",
       "      <td>[-1.612, -0.703, -0.36, -0.767, -0.601, -0.733...</td>\n",
       "      <td>None</td>\n",
       "      <td>TRW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eur-FinnishLakelands.Helama.2014</td>\n",
       "      <td>tree</td>\n",
       "      <td>temperature</td>\n",
       "      <td>Eur_005</td>\n",
       "      <td>[14.603, 14.643, 12.074, 13.898, 13.671, 13.41...</td>\n",
       "      <td>degC</td>\n",
       "      <td>MXD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dataSetName archiveType         name     TSID   \n",
       "0  Eur-SpanishPyrenees.Dorado-Linan.2012        tree        trsgi  Eur_020  \\\n",
       "1       Eur-FinnishLakelands.Helama.2014        tree  temperature  Eur_005   \n",
       "\n",
       "                                              values units proxy  \n",
       "0  [-1.612, -0.703, -0.36, -0.767, -0.601, -0.733...  None   TRW  \n",
       "1  [14.603, 14.643, 12.074, 13.898, 13.671, 13.41...  degC   MXD  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_filter = ts.filter_by_name('(temperature|trsgi)')\n",
    "\n",
    "df_paleo = ts_filter.get_timeseries_essentials()\n",
    "df_paleo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d45c1-3872-470b-aa81-efdbb975ee61",
   "metadata": {},
   "source": [
    "Our next task is to get all the information regarding time. Let's use method chaining to get the DataFrame directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14840800-69d7-450f-bc7b-c8d3a337c278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataSetName</th>\n",
       "      <th>archiveType</th>\n",
       "      <th>name</th>\n",
       "      <th>TSID</th>\n",
       "      <th>values</th>\n",
       "      <th>units</th>\n",
       "      <th>proxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eur-FinnishLakelands.Helama.2014</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYTUSB62S0A</td>\n",
       "      <td>[2000.0, 1999.0, 1998.0, 1997.0, 1996.0, 1995....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eur-NorthernScandinavia.Esper.2012</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYTECO66XAD</td>\n",
       "      <td>[-138.0, -137.0, -136.0, -135.0, -134.0, -133....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eur-SpanishPyrenees.Dorado-Linan.2012</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYT2K8MIA3N</td>\n",
       "      <td>[1260.0, 1261.0, 1262.0, 1263.0, 1264.0, 1265....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dataSetName archiveType  name         TSID   \n",
       "0       Eur-FinnishLakelands.Helama.2014        tree  year  PYTUSB62S0A  \\\n",
       "1     Eur-NorthernScandinavia.Esper.2012        tree  year  PYTECO66XAD   \n",
       "2  Eur-SpanishPyrenees.Dorado-Linan.2012        tree  year  PYT2K8MIA3N   \n",
       "\n",
       "                                              values units proxy  \n",
       "0  [2000.0, 1999.0, 1998.0, 1997.0, 1996.0, 1995....    AD  None  \n",
       "1  [-138.0, -137.0, -136.0, -135.0, -134.0, -133....    AD  None  \n",
       "2  [1260.0, 1261.0, 1262.0, 1263.0, 1264.0, 1265....    AD  None  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time = ts.filter_by_name('year').get_timeseries_essentials()\n",
    "\n",
    "df_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377da43a-7072-4614-bdb0-0b31c3f11f93",
   "metadata": {},
   "source": [
    "Now, we can use Pandas to merge the two DataFrames. In this case, we would expect that the DataFrame containing the time information would have more datasets associated with them (since not all datasets have a temoerature or trsgi value). Therefore, we want to perform a left join, dropping the unnecessary age information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cff534d5-38d1-406b-9ef7-4106a9087e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataSetName</th>\n",
       "      <th>archiveType_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>TSID_x</th>\n",
       "      <th>values_x</th>\n",
       "      <th>units_x</th>\n",
       "      <th>proxy_x</th>\n",
       "      <th>archiveType_y</th>\n",
       "      <th>name_y</th>\n",
       "      <th>TSID_y</th>\n",
       "      <th>values_y</th>\n",
       "      <th>units_y</th>\n",
       "      <th>proxy_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eur-SpanishPyrenees.Dorado-Linan.2012</td>\n",
       "      <td>tree</td>\n",
       "      <td>trsgi</td>\n",
       "      <td>Eur_020</td>\n",
       "      <td>[-1.612, -0.703, -0.36, -0.767, -0.601, -0.733...</td>\n",
       "      <td>None</td>\n",
       "      <td>TRW</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYT2K8MIA3N</td>\n",
       "      <td>[1260.0, 1261.0, 1262.0, 1263.0, 1264.0, 1265....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eur-FinnishLakelands.Helama.2014</td>\n",
       "      <td>tree</td>\n",
       "      <td>temperature</td>\n",
       "      <td>Eur_005</td>\n",
       "      <td>[14.603, 14.643, 12.074, 13.898, 13.671, 13.41...</td>\n",
       "      <td>degC</td>\n",
       "      <td>MXD</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYTUSB62S0A</td>\n",
       "      <td>[2000.0, 1999.0, 1998.0, 1997.0, 1996.0, 1995....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dataSetName archiveType_x       name_x   TSID_x   \n",
       "0  Eur-SpanishPyrenees.Dorado-Linan.2012          tree        trsgi  Eur_020  \\\n",
       "1       Eur-FinnishLakelands.Helama.2014          tree  temperature  Eur_005   \n",
       "\n",
       "                                            values_x units_x proxy_x   \n",
       "0  [-1.612, -0.703, -0.36, -0.767, -0.601, -0.733...    None     TRW  \\\n",
       "1  [14.603, 14.643, 12.074, 13.898, 13.671, 13.41...    degC     MXD   \n",
       "\n",
       "  archiveType_y name_y       TSID_y   \n",
       "0          tree   year  PYT2K8MIA3N  \\\n",
       "1          tree   year  PYTUSB62S0A   \n",
       "\n",
       "                                            values_y units_y proxy_y  \n",
       "0  [1260.0, 1261.0, 1262.0, 1263.0, 1264.0, 1265....      AD    None  \n",
       "1  [2000.0, 1999.0, 1998.0, 1997.0, 1996.0, 1995....      AD    None  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filt_merge=df_paleo.merge(df_time,how='left',on='dataSetName')\n",
    "\n",
    "df_filt_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cd412-1fc7-4415-a1d8-2633a07b9135",
   "metadata": {},
   "source": [
    "Notice the Pandas automatically changed the names of the columns to accomodate the fact that both our DataFrames had the same column names. Now let's add the location information with another left join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "895ab59f-42ff-4b93-a0fc-2fb6fafa030b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataSetName</th>\n",
       "      <th>archiveType_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>TSID_x</th>\n",
       "      <th>values_x</th>\n",
       "      <th>units_x</th>\n",
       "      <th>proxy_x</th>\n",
       "      <th>archiveType_y</th>\n",
       "      <th>name_y</th>\n",
       "      <th>TSID_y</th>\n",
       "      <th>values_y</th>\n",
       "      <th>units_y</th>\n",
       "      <th>proxy_y</th>\n",
       "      <th>geo_meanLat</th>\n",
       "      <th>geo_meanLon</th>\n",
       "      <th>geo_meanElev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eur-SpanishPyrenees.Dorado-Linan.2012</td>\n",
       "      <td>tree</td>\n",
       "      <td>trsgi</td>\n",
       "      <td>Eur_020</td>\n",
       "      <td>[-1.612, -0.703, -0.36, -0.767, -0.601, -0.733...</td>\n",
       "      <td>None</td>\n",
       "      <td>TRW</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYT2K8MIA3N</td>\n",
       "      <td>[1260.0, 1261.0, 1262.0, 1263.0, 1264.0, 1265....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "      <td>42.5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eur-FinnishLakelands.Helama.2014</td>\n",
       "      <td>tree</td>\n",
       "      <td>temperature</td>\n",
       "      <td>Eur_005</td>\n",
       "      <td>[14.603, 14.643, 12.074, 13.898, 13.671, 13.41...</td>\n",
       "      <td>degC</td>\n",
       "      <td>MXD</td>\n",
       "      <td>tree</td>\n",
       "      <td>year</td>\n",
       "      <td>PYTUSB62S0A</td>\n",
       "      <td>[2000.0, 1999.0, 1998.0, 1997.0, 1996.0, 1995....</td>\n",
       "      <td>AD</td>\n",
       "      <td>None</td>\n",
       "      <td>62.0</td>\n",
       "      <td>28.325</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dataSetName archiveType_x       name_x   TSID_x   \n",
       "0  Eur-SpanishPyrenees.Dorado-Linan.2012          tree        trsgi  Eur_020  \\\n",
       "1       Eur-FinnishLakelands.Helama.2014          tree  temperature  Eur_005   \n",
       "\n",
       "                                            values_x units_x proxy_x   \n",
       "0  [-1.612, -0.703, -0.36, -0.767, -0.601, -0.733...    None     TRW  \\\n",
       "1  [14.603, 14.643, 12.074, 13.898, 13.671, 13.41...    degC     MXD   \n",
       "\n",
       "  archiveType_y name_y       TSID_y   \n",
       "0          tree   year  PYT2K8MIA3N  \\\n",
       "1          tree   year  PYTUSB62S0A   \n",
       "\n",
       "                                            values_y units_y proxy_y   \n",
       "0  [1260.0, 1261.0, 1262.0, 1263.0, 1264.0, 1265....      AD    None  \\\n",
       "1  [2000.0, 1999.0, 1998.0, 1997.0, 1996.0, 1995....      AD    None   \n",
       "\n",
       "   geo_meanLat  geo_meanLon  geo_meanElev  \n",
       "0         42.5        1.000        1200.0  \n",
       "1         62.0       28.325         130.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filt_merge_loc=df_filt_merge.merge(df_loc,how='left',on='dataSetName')\n",
    "\n",
    "df_filt_merge_loc.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
