{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d833ae4b",
   "metadata": {},
   "source": [
    "# Reading LiPD formatted datasets with `pylipd`\n",
    "\n",
    "## Authors\n",
    "\n",
    "Deborah Khider, Varun Ratnakar\n",
    "\n",
    "Information Sciences Institute, University of Southern California\n",
    "\n",
    "Author1 = {\"name\": \"Deborah Khider\", \"affiliation\": \"Information Sciences Institute, University of Southern California\", \"email\": \"khider@usc.edu\", \"orcid\": \"0000-0001-7501-8430\"}\n",
    "\n",
    "Author2 = {\"name\": \"Varun Ratnakar\", \"affiliation\": \"Information Sciences Institute, University of Southern California\", \"email\": \"varunr@isi.edu\"}\n",
    "\n",
    "## Preamble\n",
    "\n",
    "`pylipd` is a Python package that allows you to read, manipulate, and write [LiPD](https://cp.copernicus.org/articles/12/1093/2016/cp-12-1093-2016-discussion.html#discussion) formatted datasets.\n",
    "\n",
    "### Goals\n",
    "\n",
    "* Open LiPD formatted datasets from:\n",
    "    * a local copy\n",
    "    * a web URL\n",
    "    * Our [LipdGraph database](https://linkedearth.graphdb.mint.isi.edu).\n",
    "* Add more LiPD datasets to an existing object\n",
    "\n",
    "Reading Time: 5 minutes\n",
    "\n",
    "### Keywords\n",
    "\n",
    "LiPD\n",
    "\n",
    "### Pre-requisites\n",
    "\n",
    "None. This tutorial assumes basic knowledge of Python. If you are not familiar with this coding language, check out this tutorial: http://linked.earth/ec_workshops_py/.\n",
    "\n",
    "### Relevant Packages\n",
    "\n",
    "pylipd\n",
    "\n",
    "## Data Description\n",
    "\n",
    "This notebook uses the following datasets, in LiPD format:\n",
    "\n",
    "* Nurhati, I. S., Cobb, K. M., & Di Lorenzo, E. (2011). Decadal-scale SST and salinity variations in the central tropical Pacific: Signatures of natural and anthropogenic climate change. Journal of Climate, 24(13), 3294–3308. doi:10.1175/2011jcli3852.1\n",
    "\n",
    "* Moses, C. S., Swart, P. K., and Rosenheim, B. E. (2006), Evidence of multidecadal salinity variability in the eastern tropical North Atlantic, Paleoceanography, 21, PA3010, doi:10.1029/2005PA001257.\n",
    "\n",
    "* Euro2k database: PAGES2k Consortium., Emile-Geay, J., McKay, N. et al. A global multiproxy database for temperature reconstructions of the Common Era. Sci Data 4, 170088 (2017). doi:10.1038/sdata.2017.88\n",
    "\n",
    "* Stott, L., Timmermann, A., & Thunell, R. (2007). Southern Hemisphere and deep-sea warming led deglacial atmospheric CO2 rise and tropical warming. Science (New York, N.Y.), 318(5849), 435–438. doi:10.1126/science.1143791\n",
    "\n",
    "* Tudhope, A. W., Chilcott, C. P., McCulloch, M. T., Cook, E. R., Chappell, J., Ellam, R. M., et al. (2001). Variability in the El Niño-Southern Oscillation through a glacial-interglacial cycle. Science, 291(1511), 1511-1517. doi:doi:10.1126/science.1057969\n",
    "\n",
    "* Tierney, J. E., Abram, N. J., Anchukaitis, K. J., Evans, M. N., Giry, C., Kilbourne, K. H., et al. (2015). Tropical sea surface temperatures for the past four centuries reconstructed from coral archives. Paleoceanography, 30(3), 226–252. doi:10.1002/2014pa002717\n",
    "\n",
    "* Orsi, A. J., Cornuelle, B. D., and Severinghaus, J. P. (2012), Little Ice Age cold interval in West Antarctica: Evidence from borehole temperature at the West Antarctic Ice Sheet (WAIS) Divide, Geophys. Res. Lett., 39, L09710, doi:10.1029/2012GL051260."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0be91b",
   "metadata": {},
   "source": [
    "## Demonstration\n",
    "\n",
    "`pylipd` uses object-oriented programming (OOP). In OOP, object contains the data, associated parameters (e.g., metadata) for the object and code that represents procedures that are applicable to each object. OOP is ubiquituous in Python and presents several advantages over method-oriented programming: it follows the natural relationship between an object and a method, with each call representing a clearly defined action.\n",
    "\n",
    "In `pylipd` you will only be dealing with the `LiPD` object, so you can import it directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021f5142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.lipd import LiPD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20186ddd",
   "metadata": {},
   "source": [
    "### Loading LiPD formatted datasets from a local file\n",
    "\n",
    "First let's create an empty object, in which we can load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0485ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = LiPD()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78601f1",
   "metadata": {},
   "source": [
    "Now let's load our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "100a98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 LiPD files\n",
      "Conversion to RDF done..\n",
      "Loading RDF into graph\n",
      "Loaded..\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/Ocn-Palmyra.Nurhati.2011.lpd'\n",
    "D.load(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82363c",
   "metadata": {},
   "source": [
    "If you want to see the dataset names contained in your object easily, you can use this function, which returns a list of dataset names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "941de4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ocn-Palmyra.Nurhati.2011']\n"
     ]
    }
   ],
   "source": [
    "names = D.get_all_dataset_names()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ab1f6a",
   "metadata": {},
   "source": [
    "### Loading a LiPD formatted datasets from a url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b5fe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 LiPD files\n",
      "Conversion to RDF done..\n",
      "Loading RDF into graph\n",
      "Loaded..\n"
     ]
    }
   ],
   "source": [
    "data_url = 'https://lipdverse.org/data/iso2k100_CO06MOPE/1_0_2//CO06MOPE.lpd'\n",
    "\n",
    "D2=LiPD()\n",
    "D2.load(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25eb9c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CO06MOPE']\n"
     ]
    }
   ],
   "source": [
    "names = D2.get_all_dataset_names()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b2ed3",
   "metadata": {},
   "source": [
    "If you want to work with both files together, you can simply load the new dataset into your existing object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea5da3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 LiPD files\n",
      "Conversion to RDF done..\n",
      "Loading RDF into graph\n",
      "Loaded..\n",
      "['Ocn-Palmyra.Nurhati.2011', 'CO06MOPE']\n"
     ]
    }
   ],
   "source": [
    "D.load(data_url)\n",
    "\n",
    "names = D.get_all_dataset_names()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8792ac9",
   "metadata": {},
   "source": [
    "You can also create the object directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b4d7063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2 LiPD files\n",
      "Conversion to RDF done..\n",
      "Loading RDF into graph\n",
      "Loaded..\n",
      "['Ocn-Palmyra.Nurhati.2011', 'CO06MOPE']\n"
     ]
    }
   ],
   "source": [
    "data = ['../data/Ocn-Palmyra.Nurhati.2011.lpd', 'https://lipdverse.org/data/iso2k100_CO06MOPE/1_0_2//CO06MOPE.lpd']\n",
    "\n",
    "D3=LiPD()\n",
    "D3.load(data)\n",
    "\n",
    "names = D3.get_all_dataset_names()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73c89c3",
   "metadata": {},
   "source": [
    "### Loading from a directory\n",
    "\n",
    "\n",
    "Let's load some of the datasets contained in the Euro2k database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf9f1a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 31 LiPD files\n",
      "Conversion to RDF done..\n",
      "Loading RDF into graph\n",
      "Loaded..\n"
     ]
    }
   ],
   "source": [
    "path = '../data/Euro2k/'\n",
    "\n",
    "D_dir = LiPD()\n",
    "D_dir.load_from_dir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1193ff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ocn-RedSea.Felis.2000', 'Arc-Forfjorddalen.McCarroll.2013', 'Eur-Tallinn.Tarand.2001', 'Eur-CentralEurope.Dobrovoln_.2009', 'Eur-EuropeanAlps.B_ntgen.2011', 'Eur-CentralandEasternPyrenees.Pla.2004', 'Arc-Tjeggelvas.Bjorklund.2012', 'Arc-Indigirka.Hughes.1999', 'Eur-SpannagelCave.Mangini.2005', 'Ocn-AqabaJordanAQ19.Heiss.1999', 'Arc-Jamtland.Wilson.2016', 'Eur-RAPiD-17-5P.Moffa-Sanchez.2014', 'Eur-LakeSilvaplana.Trachsel.2010', 'Eur-NorthernSpain.Mart_n-Chivelet.2011', 'Eur-MaritimeFrenchAlps.B_ntgen.2012', 'Ocn-AqabaJordanAQ18.Heiss.1999', 'Arc-Tornetrask.Melvin.2012', 'Eur-EasternCarpathianMountains.Popa.2008', 'Arc-PolarUrals.Wilson.2015', 'Eur-LakeSilvaplana.Larocque-Tobler.2010', 'Eur-CoastofPortugal.Abrantes.2011', 'Eur-TatraMountains.B_ntgen.2013', 'Eur-SpanishPyrenees.Dorado-Linan.2012', 'Eur-FinnishLakelands.Helama.2014', 'Eur-Seebergsee.Larocque-Tobler.2012', 'Eur-NorthernScandinavia.Esper.2012', 'Arc-GulfofAlaska.Wilson.2014', 'Arc-Kittelfjall.Bjorklund.2012', 'Eur-L_tschental.B_ntgen.2006', 'Eur-Stockholm.Leijonhufvud.2009', 'Arc-AkademiiNaukIceCap.Opel.2013']\n"
     ]
    }
   ],
   "source": [
    "names = D_dir.get_all_dataset_names()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f27bf73",
   "metadata": {},
   "source": [
    "You can still load single files using the method described above and append them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f482c39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 LiPD files\n",
      "Conversion to RDF done..\n",
      "Loading RDF into graph\n",
      "Loaded..\n",
      "['Ocn-RedSea.Felis.2000', 'Arc-Forfjorddalen.McCarroll.2013', 'Eur-Tallinn.Tarand.2001', 'Eur-CentralEurope.Dobrovoln_.2009', 'Eur-EuropeanAlps.B_ntgen.2011', 'Eur-CentralandEasternPyrenees.Pla.2004', 'Arc-Tjeggelvas.Bjorklund.2012', 'Arc-Indigirka.Hughes.1999', 'Eur-SpannagelCave.Mangini.2005', 'Ocn-AqabaJordanAQ19.Heiss.1999', 'Arc-Jamtland.Wilson.2016', 'Eur-RAPiD-17-5P.Moffa-Sanchez.2014', 'Eur-LakeSilvaplana.Trachsel.2010', 'Eur-NorthernSpain.Mart_n-Chivelet.2011', 'Eur-MaritimeFrenchAlps.B_ntgen.2012', 'Ocn-AqabaJordanAQ18.Heiss.1999', 'Arc-Tornetrask.Melvin.2012', 'Eur-EasternCarpathianMountains.Popa.2008', 'Arc-PolarUrals.Wilson.2015', 'Eur-LakeSilvaplana.Larocque-Tobler.2010', 'Eur-CoastofPortugal.Abrantes.2011', 'Eur-TatraMountains.B_ntgen.2013', 'Eur-SpanishPyrenees.Dorado-Linan.2012', 'Eur-FinnishLakelands.Helama.2014', 'Eur-Seebergsee.Larocque-Tobler.2012', 'Eur-NorthernScandinavia.Esper.2012', 'Arc-GulfofAlaska.Wilson.2014', 'Arc-Kittelfjall.Bjorklund.2012', 'Eur-L_tschental.B_ntgen.2006', 'Eur-Stockholm.Leijonhufvud.2009', 'Arc-AkademiiNaukIceCap.Opel.2013', 'CO06MOPE']\n"
     ]
    }
   ],
   "source": [
    "D_dir.load(data_url)\n",
    "\n",
    "names = D_dir.get_all_dataset_names()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eadfc12",
   "metadata": {},
   "source": [
    "### Loading from the remote LipdGraph database\n",
    "\n",
    "Files stored on the [LiPDverse](https://lipdverse.org) are also available in a [graph database](https://linkedearth.graphdb.mint.isi.edu), which supports complex querying through the [SPARQL](https://en.wikipedia.org/wiki/SPARQL) query language. `pylipd` essentially wraps these complex queries into Python calls to facilitate the manipulation of the datasets. \n",
    "\n",
    "To load a file from the remote database, all you need to know is the dataset name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8ab558e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching datasets from remote endpoint..\n",
      "Making remote query to endpoint: https://linkedearth.graphdb.mint.isi.edu/repositories/LiPDVerse2\n",
      "Done..\n",
      "['Ocn-MadangLagoonPapuaNewGuinea.Kuhnert.2001', 'MD98_2181.Stott.2007', 'Ant-WAIS-Divide.Severinghaus.2012']\n"
     ]
    }
   ],
   "source": [
    "lipd_remote = LiPD()\n",
    "lipd_remote.set_endpoint(\"https://linkedearth.graphdb.mint.isi.edu/repositories/LiPDVerse2\")\n",
    "lipd_remote.load_remote_datasets([\"Ocn-MadangLagoonPapuaNewGuinea.Kuhnert.2001\", \"MD98_2181.Stott.2007\", \"Ant-WAIS-Divide.Severinghaus.2012\"])\n",
    "\n",
    "print(lipd_remote.get_all_dataset_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b418725",
   "metadata": {},
   "source": [
    "### Loading in parallel\n",
    "\n",
    "If you plan on loading mulitple LiPD files (hundreds to thousands), you may want to do so in parallel. If you choose to do so, you need to use the `if __name__ == \"__main__\" ` notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59efb943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 31 LiPD files\n",
      "Conversion to RDF done..\n",
      "Loading RDF into graph\n",
      "Loaded..\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    D_parallel = LiPD()\n",
    "    D_parallel.load_from_dir(path, parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2be25",
   "metadata": {},
   "source": [
    "After the intial loading, you can resume using your object directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2befb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ocn-RedSea.Felis.2000', 'Arc-Forfjorddalen.McCarroll.2013', 'Eur-Tallinn.Tarand.2001', 'Eur-CentralEurope.Dobrovoln_.2009', 'Eur-EuropeanAlps.B_ntgen.2011', 'Eur-CentralandEasternPyrenees.Pla.2004', 'Arc-Tjeggelvas.Bjorklund.2012', 'Arc-Indigirka.Hughes.1999', 'Eur-SpannagelCave.Mangini.2005', 'Ocn-AqabaJordanAQ19.Heiss.1999', 'Arc-Jamtland.Wilson.2016', 'Eur-RAPiD-17-5P.Moffa-Sanchez.2014', 'Eur-LakeSilvaplana.Trachsel.2010', 'Eur-NorthernSpain.Mart_n-Chivelet.2011', 'Eur-MaritimeFrenchAlps.B_ntgen.2012', 'Ocn-AqabaJordanAQ18.Heiss.1999', 'Arc-Tornetrask.Melvin.2012', 'Eur-EasternCarpathianMountains.Popa.2008', 'Arc-PolarUrals.Wilson.2015', 'Eur-LakeSilvaplana.Larocque-Tobler.2010', 'Eur-CoastofPortugal.Abrantes.2011', 'Eur-TatraMountains.B_ntgen.2013', 'Eur-SpanishPyrenees.Dorado-Linan.2012', 'Eur-FinnishLakelands.Helama.2014', 'Eur-Seebergsee.Larocque-Tobler.2012', 'Eur-NorthernScandinavia.Esper.2012', 'Arc-GulfofAlaska.Wilson.2014', 'Arc-Kittelfjall.Bjorklund.2012', 'Eur-L_tschental.B_ntgen.2006', 'Eur-Stockholm.Leijonhufvud.2009', 'Arc-AkademiiNaukIceCap.Opel.2013']\n"
     ]
    }
   ],
   "source": [
    "print(D_parallel.get_all_dataset_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8efeaad",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b> Note: </b> Once datasets are loaded into the object with one of the methods described above, you can always append more using a different method.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac519019",
   "metadata": {},
   "source": [
    "### Merging LiPD objects\n",
    "\n",
    "In the course of your work, you may need to merge two `LiPD` objects together. Let's merge `D` into `D_parallel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6d3c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ocn-RedSea.Felis.2000', 'Arc-Forfjorddalen.McCarroll.2013', 'Eur-Tallinn.Tarand.2001', 'Eur-CentralEurope.Dobrovoln_.2009', 'Eur-EuropeanAlps.B_ntgen.2011', 'Eur-CentralandEasternPyrenees.Pla.2004', 'Arc-Tjeggelvas.Bjorklund.2012', 'Arc-Indigirka.Hughes.1999', 'Eur-SpannagelCave.Mangini.2005', 'Ocn-AqabaJordanAQ19.Heiss.1999', 'Arc-Jamtland.Wilson.2016', 'Eur-RAPiD-17-5P.Moffa-Sanchez.2014', 'Eur-LakeSilvaplana.Trachsel.2010', 'Eur-NorthernSpain.Mart_n-Chivelet.2011', 'Eur-MaritimeFrenchAlps.B_ntgen.2012', 'Ocn-AqabaJordanAQ18.Heiss.1999', 'Arc-Tornetrask.Melvin.2012', 'Eur-EasternCarpathianMountains.Popa.2008', 'Arc-PolarUrals.Wilson.2015', 'Eur-LakeSilvaplana.Larocque-Tobler.2010', 'Eur-CoastofPortugal.Abrantes.2011', 'Eur-TatraMountains.B_ntgen.2013', 'Eur-SpanishPyrenees.Dorado-Linan.2012', 'Eur-FinnishLakelands.Helama.2014', 'Eur-Seebergsee.Larocque-Tobler.2012', 'Eur-NorthernScandinavia.Esper.2012', 'Arc-GulfofAlaska.Wilson.2014', 'Arc-Kittelfjall.Bjorklund.2012', 'Eur-L_tschental.B_ntgen.2006', 'Eur-Stockholm.Leijonhufvud.2009', 'Arc-AkademiiNaukIceCap.Opel.2013']\n"
     ]
    }
   ],
   "source": [
    "D_parallel.merge(D)\n",
    "\n",
    "print(D_parallel.get_all_dataset_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f383f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ocn-Palmyra.Nurhati.2011', 'CO06MOPE']\n"
     ]
    }
   ],
   "source": [
    "print(D.get_all_dataset_names())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
