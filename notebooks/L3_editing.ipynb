{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a95851d-69de-4f1f-ab37-542c120f3752",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/LinkedEarth/Logos/blob/master/pyLiPD_logo1_transparent.png?raw=true\">\n",
    "\n",
    "# Editing LiPD Files\n",
    "\n",
    "## Authors\n",
    "\n",
    "[Deborah Khider](https://orcid.org/0000-0001-7501-8430)\n",
    "\n",
    "\n",
    "## Preamble\n",
    "\n",
    "Now that we have learned about the [`Dataset` class](L3_dataset_class.ipynb) and how to extract information from it, let's edit a LiPD file. We will be considering three main instances of editing: (1) changing exisiting information, (2) adding new metadata, and (3) adding an ensemble table. \n",
    "\n",
    "Before we start, have a look at the [documentation on the LiPD classes module](https://pylipd.readthedocs.io/en/latest/api.html#lipd-classes). If you click on any of the classes, you should notice a pattern in the associated methods:\n",
    "* `get` + PropertyName allows you to retrieve to values associated with a property\n",
    "* `set` + PropertyName allows you to set or change the value for an exisiting property value with another one of type string, float, integer, boolean. If the property value is a list, set will replace any exisitng value already present in the metadata (refer to the diagram below for the expected type). \n",
    "* `add` + PropertyName allows you to set or add a value for an exisiting property that takes a list.\n",
    "\n",
    "In addition, there are two functionalies that allow you to add your custom properties: `set_non_standard_property` and `add_non_standard_property`. For now, these properties can only be used for values that do not require a new class to be created. \n",
    "\n",
    "![image](https://github.com/LinkedEarth/pylipd/blob/main/examples/notebooks/UMLDiagram.png?raw=true)\n",
    "\n",
    "### Goals\n",
    "\n",
    "* Edit a LiPD-formatted dataset\n",
    "* Adding information in a new object (e.g., publication information)\n",
    "* Adding an ensemble table \n",
    "* Save the edited dataset to a new file\n",
    "\n",
    "Reading Time: 5 minutes\n",
    "\n",
    "### Keywords\n",
    "\n",
    "LiPD, LinkedEarth Ontology, Object-Oriented Programming\n",
    "\n",
    "### Pre-requisites\n",
    "\n",
    "An understanding of OOP and the LinkedEarth Ontology. Completion of [Dataset class example](L3_dataset_class.ipynb).\n",
    "\n",
    "## Data Description\n",
    "\n",
    "We will be working with an hypothetical marine sedimentary record of $\\delta^{18}$O and Mg/Ca so we can edit the file without worrying about accuracy in a specific record. The idealized record was converted into the LiPD format using the [LiPD playground](https://lipd.net/playground) and is made available on the GitHub repository for these tutorials. \n",
    "\n",
    "## Demonstration\n",
    "\n",
    "Let's import the necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9b81477-caa7-4dc7-a892-f739751476a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.classes.dataset import Dataset\n",
    "from pylipd.lipd import LiPD\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8babac-8d41-47b0-9498-d8108b6ac48a",
   "metadata": {},
   "source": [
    "Let's load our idealized dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470a2157-4eed-423f-bff1-8aa1785b3c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 LiPD files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 31.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = '../data/MyWonderfulRecord.LinkedEarth.2024.lpd'\n",
    "D = LiPD()\n",
    "D.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e84fd-5692-4edd-9ea6-3bdc3316885e",
   "metadata": {},
   "source": [
    "Now, let's export to a `Dataset` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a461d64e-2512-4cd7-af4b-99367f2bf6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = D.get_datasets()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e34f94-ef25-429e-a71a-3915abfa058c",
   "metadata": {},
   "source": [
    "### Editing an exisiting property\n",
    "\n",
    "For this example, we will assume that there is an error in the geographical coordinates and we will correct the longitude. First, we need to get to the `geo` object. When in doubt on how to navigate the file, you can use the [LinkedEarth ontology](https://linked.earth/ontology/) to help you or the handy diagram above shown in the preamble.\n",
    "\n",
    "From this, you can see that the information associated with the `Location` can be obtained from the `Dataset`. A quick check from the [documentation](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.dataset.Dataset) tells you that you can use the `getLocation` function to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d57982-2b09-4899-87bf-464e1c8bbb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo = ds.getLocation()\n",
    "lon = geo.getLongitude()\n",
    "\n",
    "lon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf2280e-d76b-4cb6-86a5-33f40f04721e",
   "metadata": {},
   "source": [
    "To change the exsiting longitude information to the corrected value (here, we will assume 165.9), you can use [the `setLongitude`](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.location.Location.setLongitude) function. Notice that the longitude value should be input as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cacaf9ae-74ac-4024-9118-f4daaefb6bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'165.9'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo.setLongitude('165.9')\n",
    "geo.getLongitude()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a3b60f-6288-455a-b58a-1118343cb0e2",
   "metadata": {},
   "source": [
    "We have succcessfully changed the longitude to its correct value! You can also use the `set` + PropertyName functions to add information (not just correct it). For instance, this record doesn't have a `SiteName`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "826138cf-0ee5-4c86-830b-00bdefcd6d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo.getSiteName()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb9ec0-7b70-4508-b643-adbc57101204",
   "metadata": {},
   "source": [
    "Let's change this to `WonderfulCore`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de1592d-47bf-4e88-ba07-3b804bd1c576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WonderfulCore'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo.setSiteName('WonderfulCore')\n",
    "geo.getSiteName()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ca108-cd6f-41cd-9957-997d69d02bef",
   "metadata": {},
   "source": [
    "So far, we have looked at adding or editing the values of exisiting properties. \n",
    "\n",
    "### Creating new properties\n",
    "\n",
    "Many datasets on the [Lipdverse](https://lipdverse.org) and associated [LiPDGraph](https://linkedearth.graphdb.mint.isi.edu) come from working groups compiling datasets for a particular purpose. In this case, it may be useful to create a temporary property associated with a specific variable (i.e., column) in the dataset to indicate its use for an analysis. For instance, the [Pages2k Temperature working group](https://lipdverse.org/project/pages2k/) used the property `usedInGlobalTemperatureAnalysis` as a flag to represent the column to be used for temperature reconstructions. \n",
    "\n",
    "As an example, we will add a property called `forTempAnalysis` to the variable Temperature in our dataset. To do so, you can use the `set_non_standard_property` function. This function is available for each of the classes present in `PyLiPD` and takes a \"key,value\" pair an input with the key representing the property name and the value the value associated with the property. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbfbd1d8-6a6d-449b-8e4f-9cf69ec796db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'temperature?s?' #look for temperature or temperatures in the varname\n",
    " \n",
    "for pdata in ds.getPaleoData(): # loop through all possible paleodata object\n",
    "    for table in pdata.getMeasurementTables(): # Loop through the measurement tables\n",
    "        for var in table.getVariables(): # Loop through the variables in the table\n",
    "            if re.search(pattern, var.getName(), re.IGNORECASE):\n",
    "                var.set_non_standard_property('forTempAnalysis',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799272f-a479-4eff-89db-d4da5d228cb2",
   "metadata": {},
   "source": [
    "### Adding new information from classes\n",
    "\n",
    "#### Adding Publication information\n",
    "\n",
    "You may have several publications associated with a particular dataset. Therefore, publications are set in a list, in which each item represent a Publication object.  When you want to do so in `PyLiPD`, you will be using functions of the form `add` + PropertyName. \n",
    "\n",
    "Let's add a publication to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c1126ce-8ffa-48bf-a3e1-ca3012e44d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.classes.publication import Publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25334b8a-fa96-45a9-915a-30c0b2de8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = Publication() # instantiate the object\n",
    "pub.setTitle('Publication Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c1793-0309-491e-9142-df1275b395da",
   "metadata": {},
   "source": [
    "Now that we have created the object and entered the title, let's add authors. Looking at the diagram in the preamble, authors can be set as a list of `Person`. Let's create two authors and add them to our publication object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d30d558-5110-48cb-993b-0d0462f32c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.classes.person import Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "016fb9a3-4aa5-4bab-8625-f43cd4966a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "person1 = Person(); person1.setName(\"Deborah Khider\")\n",
    "person2 = Person(); person2.setName(\"Varun Ratnakar\")\n",
    "pub.setAuthors([person1, person2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf35c23-dd8e-4689-b484-acd57a6895ac",
   "metadata": {},
   "source": [
    "Let's add a few more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcafbe82-e743-4a99-9437-540a8afc602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub.setJournal('Journal Name')\n",
    "pub.setPages('1-12')\n",
    "pub.setVolume('1')\n",
    "pub.setYear('2014')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d251b51-7572-4de3-b5cf-87b84c47559f",
   "metadata": {},
   "source": [
    "Let's add the Publication information to our `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6eb962-6434-479d-add7-d77f7191eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.addPublication(pub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b64913-08b7-4151-ad42-f480fb384933",
   "metadata": {},
   "source": [
    "Ok, let's have a look at our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6af92dbd-c15a-4410-a91f-a21d308cd94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publication Title\n"
     ]
    }
   ],
   "source": [
    "print(ds.getPublications()[0].getTitle())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086afc98-c0d9-4f94-9b20-7657c0b152ef",
   "metadata": {},
   "source": [
    "#### Adding an Ensemble Table\n",
    "\n",
    "A common task in paleoclimate studies is to create possible realizations of the age model using Bayesian age modeling software such as [Bchron](https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9876.2008.00623.x)(Haslett and Parnell, 2008), [BACON](https://projecteuclid.org/journals/bayesian-analysis/volume-6/issue-3/Flexible-paleoclimate-age-depth-models-using-an-autoregressive-gamma-process/10.1214/11-BA618.full)(Blaauw and Christen, 2011), or [OxCal](https://c14.arch.ox.ac.uk/oxcalhelp/hlp_analysis_oper.html)(Bronk Ramsey, 2008). \n",
    "\n",
    "For this example, we will create a \"dummy\" ensemble table as a [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html) from the existing data.\n",
    "\n",
    "So first, let's grab the age values from the measurement table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17b1b06e-1c90-414d-93ec-6ded7e8ae524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>temperature</th>\n",
       "      <th>Mg/Ca</th>\n",
       "      <th>d18O</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981.30</td>\n",
       "      <td>28.686774</td>\n",
       "      <td>5.023996</td>\n",
       "      <td>-4.176004</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961.30</td>\n",
       "      <td>28.853606</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>-4.100000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1946.37</td>\n",
       "      <td>29.017971</td>\n",
       "      <td>5.176004</td>\n",
       "      <td>-4.023996</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1952.00</td>\n",
       "      <td>29.661152</td>\n",
       "      <td>5.484465</td>\n",
       "      <td>-3.715535</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1906.37</td>\n",
       "      <td>27.982737</td>\n",
       "      <td>4.715535</td>\n",
       "      <td>-4.484465</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  temperature     Mg/Ca      d18O  depth\n",
       "0  1981.30    28.686774  5.023996 -4.176004    0.5\n",
       "1  1961.30    28.853606  5.100000 -4.100000    1.0\n",
       "2  1946.37    29.017971  5.176004 -4.023996    1.5\n",
       "3  1952.00    29.661152  5.484465 -3.715535    2.0\n",
       "4  1906.37    27.982737  4.715535 -4.484465    2.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tables = []\n",
    "\n",
    "for paleoData in ds.getPaleoData(): # loop over the various PaleoData objects\n",
    "    for table in paleoData.getMeasurementTables(): #get the measurement tables\n",
    "        df = table.getDataFrame(use_standard_names=True) # grab the data and standardize the variable names\n",
    "        data_tables.append(df)\n",
    "\n",
    "data_tables[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7762665-cde7-476f-a274-fe487e1a1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "time  = data_tables[0]['year'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef0323-9b1a-4e51-aea9-9f56af22c076",
   "metadata": {},
   "source": [
    "Create 1000 realizations of the age ensemble by using a normal distribution centered around the `time` vector with a standard deviation of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58d946f7-a318-45cc-91ee-1671d1dffd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 5\n",
    "num_draws = 1000\n",
    "\n",
    "#Generate ensemble\n",
    "ens = np.random.normal(loc=time[:, np.newaxis], scale=std_dev, size=(len(time), num_draws))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d868c08-cb22-478c-9c01-8b1e67edc0fb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Make sure that the number of realization of the age ensembles correspond to the number of columns in your array\n",
    "</div>\n",
    "\n",
    "Next, let's inset the table into our dataset. First, let's check if there are any `ChronData` object we should attach the table to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e557a92-e3c4-4a4e-87d3-50fb9f71027d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.getChronData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1268a01-fa19-4039-afb1-700351b931a4",
   "metadata": {},
   "source": [
    "Since there are none, let's create a `ChronData` object: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177843ff-442b-47a7-aac1-314ed279854c",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Blaauw, M., & Christen, J. A. (2011). Flexible Paleoclimate Age-Depth Models using an Autoregressive Gamma Process. Bayesian Analysis, 6(3), 457-474.\n",
    "\n",
    "- Bronk Ramsey, C. (2008). Deposition models for chronological records, Quaternary Sci. Rev., 27, 42–60. \n",
    "\n",
    "- Haslett, J., & Parnell, A. (2008). A simple monotone process with application to radiocarbon-dated depth chronologies. Journal of the Royal Statistical Society C, 57, 399-418."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1699912-f781-41a3-a34b-06d148ebca33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
