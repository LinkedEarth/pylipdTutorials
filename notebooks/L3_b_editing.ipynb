{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a95851d-69de-4f1f-ab37-542c120f3752",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/LinkedEarth/Logos/blob/master/PyLiPD/pyLiPD_logo1_transparent.png?raw=true\" width =\"800\">\n",
    "\n",
    "# Editing LiPD Files\n",
    "\n",
    "## Authors\n",
    "\n",
    "[Deborah Khider](https://orcid.org/0000-0001-7501-8430)\n",
    "\n",
    "\n",
    "## Preamble\n",
    "\n",
    "Now that we have learned about the [`Dataset` class](L3_dataset_class.ipynb) and how to extract information from it, let's edit a LiPD file. We will be considering three main instances of editing: (1) changing exisiting information, (2) adding new metadata, and (3) adding an ensemble table. \n",
    "\n",
    "Before we start, have a look at the [documentation on the LiPD classes module](https://pylipd.readthedocs.io/en/latest/api.html#lipd-classes). If you click on any of the classes, you should notice a pattern in the associated methods:\n",
    "* `get` + PropertyName allows you to retrieve to values associated with a property\n",
    "* `set` + PropertyName allows you to set or change the value for an exisiting property value with another one of type string, float, integer, boolean. If the property value is a list, set will replace any exisitng value already present in the metadata (refer to the diagram below for the expected type). \n",
    "* `add` + PropertyName allows you to set or add a value for an exisiting property that takes a list.\n",
    "\n",
    "In addition, there are two functionalies that allow you to add your custom properties: `set_non_standard_property` and `add_non_standard_property`. For now, these properties can only be used for values that do not require a new class to be created. \n",
    "\n",
    "![image](https://github.com/LinkedEarth/pylipd/blob/main/examples/notebooks/UMLDiagram.png?raw=true)\n",
    "\n",
    "### Goals\n",
    "\n",
    "* Edit a LiPD-formatted dataset\n",
    "* Adding information in a new object (e.g., publication information)\n",
    "* Adding an ensemble table \n",
    "* Save the edited dataset to a new file\n",
    "\n",
    "Reading Time: 10 minutes\n",
    "\n",
    "### Keywords\n",
    "\n",
    "LiPD, LinkedEarth Ontology, Object-Oriented Programming\n",
    "\n",
    "### Pre-requisites\n",
    "\n",
    "An understanding of OOP and the LinkedEarth Ontology. Completion of [Dataset class example](L3_dataset_class.ipynb).\n",
    "\n",
    "## Data Description\n",
    "\n",
    "We will be working with an hypothetical marine sedimentary record of $\\delta^{18}$O and Mg/Ca so we can edit the file without worrying about accuracy in a specific record. The idealized record was converted into the LiPD format using the [LiPD playground](https://lipd.net/playground) and is made available on the GitHub repository for these tutorials. \n",
    "\n",
    "## Demonstration\n",
    "\n",
    "Let's import the necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b81477-caa7-4dc7-a892-f739751476a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.classes.dataset import Dataset\n",
    "from pylipd.lipd import LiPD\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec1f7a6-c754-4a78-bd19-2073d183516e",
   "metadata": {},
   "source": [
    "The next cell allows generating unique identifier for variables called TSID in LiPD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f88d6a6-8363-4dcd-a4a6-ec61c6bf0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def generate_unique_id(prefix='PYD'):\n",
    "    # Generate a random UUID\n",
    "    random_uuid = uuid.uuid4()  # Generates a random UUID.\n",
    "    \n",
    "    # Convert UUID format to the specific format we need\n",
    "    # UUID is usually in the form '1e2a2846-2048-480b-9ec6-674daef472bd' so we slice and insert accordingly\n",
    "    id_str = str(random_uuid)\n",
    "    formatted_id = f\"{prefix}-{id_str[:5]}-{id_str[9:13]}-{id_str[14:18]}-{id_str[19:23]}-{id_str[24:28]}\"\n",
    "    \n",
    "    return formatted_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8babac-8d41-47b0-9498-d8108b6ac48a",
   "metadata": {},
   "source": [
    "Let's load our idealized dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470a2157-4eed-423f-bff1-8aa1785b3c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 LiPD files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 41.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = '../data/MyWonderfulRecord.LinkedEarth.2024.lpd'\n",
    "D = LiPD()\n",
    "D.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e84fd-5692-4edd-9ea6-3bdc3316885e",
   "metadata": {},
   "source": [
    "Now, let's export to a `Dataset` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a461d64e-2512-4cd7-af4b-99367f2bf6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = D.get_datasets()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e34f94-ef25-429e-a71a-3915abfa058c",
   "metadata": {},
   "source": [
    "### Editing an exisiting property\n",
    "\n",
    "For this example, we will assume that there is an error in the geographical coordinates and we will correct the longitude. First, we need to get to the `geo` object. When in doubt on how to navigate the file, you can use the [LinkedEarth ontology](https://linked.earth/ontology/) to help you or the handy diagram above shown in the preamble.\n",
    "\n",
    "From this, you can see that the information associated with the `Location` can be obtained from the `Dataset`. A quick check from the [documentation](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.dataset.Dataset) tells you that you can use the `getLocation` function to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d57982-2b09-4899-87bf-464e1c8bbb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo = ds.getLocation()\n",
    "lon = geo.getLongitude()\n",
    "\n",
    "lon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf2280e-d76b-4cb6-86a5-33f40f04721e",
   "metadata": {},
   "source": [
    "To change the exsiting longitude information to the corrected value (here, we will assume 165.9), you can use [the `setLongitude`](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.location.Location.setLongitude) function. Notice that the longitude value should be input as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cacaf9ae-74ac-4024-9118-f4daaefb6bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'165.9'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo.setLongitude('165.9')\n",
    "geo.getLongitude()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a3b60f-6288-455a-b58a-1118343cb0e2",
   "metadata": {},
   "source": [
    "We have succcessfully changed the longitude to its correct value! You can also use the `set` + PropertyName functions to add information (not just correct it). For instance, this record doesn't have a `SiteName`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826138cf-0ee5-4c86-830b-00bdefcd6d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo.getSiteName()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb9ec0-7b70-4508-b643-adbc57101204",
   "metadata": {},
   "source": [
    "Let's change this to `WonderfulCore`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9de1592d-47bf-4e88-ba07-3b804bd1c576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WonderfulCore'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo.setSiteName('WonderfulCore')\n",
    "geo.getSiteName()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ca108-cd6f-41cd-9957-997d69d02bef",
   "metadata": {},
   "source": [
    "So far, we have looked at adding or editing the values of exisiting properties. \n",
    "\n",
    "### Creating new properties\n",
    "\n",
    "Many datasets on the [Lipdverse](https://lipdverse.org) and associated [LiPDGraph](https://linkedearth.graphdb.mint.isi.edu) come from working groups compiling datasets for a particular purpose. In this case, it may be useful to create a temporary property associated with a specific variable (i.e., column) in the dataset to indicate its use for an analysis. For instance, the [Pages2k Temperature working group](https://lipdverse.org/project/pages2k/) used the property `usedInGlobalTemperatureAnalysis` as a flag to represent the column to be used for temperature reconstructions. \n",
    "\n",
    "As an example, we will add a property called `forTempAnalysis` to the variable Temperature in our dataset. To do so, you can use the `set_non_standard_property` function. This function is available for each of the classes present in `PyLiPD` and takes a \"key,value\" pair an input with the key representing the property name and the value the value associated with the property. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbfbd1d8-6a6d-449b-8e4f-9cf69ec796db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'temperature?s?' #look for temperature or temperatures in the varname\n",
    " \n",
    "for pdata in ds.getPaleoData(): # loop through all possible paleodata object\n",
    "    for table in pdata.getMeasurementTables(): # Loop through the measurement tables\n",
    "        for var in table.getVariables(): # Loop through the variables in the table\n",
    "            if re.search(pattern, var.getName(), re.IGNORECASE):\n",
    "                var.set_non_standard_property('forTempAnalysis',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799272f-a479-4eff-89db-d4da5d228cb2",
   "metadata": {},
   "source": [
    "### Adding new information from classes\n",
    "\n",
    "#### Adding Publication information\n",
    "\n",
    "You may have several publications associated with a particular dataset. Therefore, publications are set in a list, in which each item represent a Publication object.  When you want to do so in `PyLiPD`, you will be using functions of the form `add` + PropertyName. \n",
    "\n",
    "Let's add a publication to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c1126ce-8ffa-48bf-a3e1-ca3012e44d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.classes.publication import Publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25334b8a-fa96-45a9-915a-30c0b2de8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = Publication() # instantiate the object\n",
    "pub.setTitle('Publication Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c1793-0309-491e-9142-df1275b395da",
   "metadata": {},
   "source": [
    "Now that we have created the object and entered the title, let's add authors. Looking at the diagram in the preamble, authors can be set as a list of `Person`. Let's create two authors and add them to our publication object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d30d558-5110-48cb-993b-0d0462f32c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.classes.person import Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "016fb9a3-4aa5-4bab-8625-f43cd4966a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "person1 = Person(); person1.setName(\"Deborah Khider\")\n",
    "person2 = Person(); person2.setName(\"Varun Ratnakar\")\n",
    "pub.setAuthors([person1, person2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf35c23-dd8e-4689-b484-acd57a6895ac",
   "metadata": {},
   "source": [
    "Let's add a few more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcafbe82-e743-4a99-9437-540a8afc602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub.setJournal('Journal Name')\n",
    "pub.setPages('1-12')\n",
    "pub.setVolume('1')\n",
    "pub.setYear('2014')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d251b51-7572-4de3-b5cf-87b84c47559f",
   "metadata": {},
   "source": [
    "Let's add the Publication information to our `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6eb962-6434-479d-add7-d77f7191eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.addPublication(pub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b64913-08b7-4151-ad42-f480fb384933",
   "metadata": {},
   "source": [
    "Ok, let's have a look at our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6af92dbd-c15a-4410-a91f-a21d308cd94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publication Title\n"
     ]
    }
   ],
   "source": [
    "print(ds.getPublications()[0].getTitle())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086afc98-c0d9-4f94-9b20-7657c0b152ef",
   "metadata": {},
   "source": [
    "#### Adding an Ensemble Table\n",
    "\n",
    "A common task in paleoclimate studies is to create possible realizations of the age model using Bayesian age modeling software such as [Bchron](https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9876.2008.00623.x)(Haslett and Parnell, 2008), [BACON](https://projecteuclid.org/journals/bayesian-analysis/volume-6/issue-3/Flexible-paleoclimate-age-depth-models-using-an-autoregressive-gamma-process/10.1214/11-BA618.full)(Blaauw and Christen, 2011), or [OxCal](https://c14.arch.ox.ac.uk/oxcalhelp/hlp_analysis_oper.html)(Bronk Ramsey, 2008). \n",
    "\n",
    "For this example, we will create a \"dummy\" ensemble table as a [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html) from the existing data.\n",
    "\n",
    "So first, let's grab the age values from the measurement table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17b1b06e-1c90-414d-93ec-6ded7e8ae524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>Mg/Ca</th>\n",
       "      <th>year</th>\n",
       "      <th>temperature</th>\n",
       "      <th>d18O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>5.023996</td>\n",
       "      <td>1981.30</td>\n",
       "      <td>28.686774</td>\n",
       "      <td>-4.176004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1961.30</td>\n",
       "      <td>28.853606</td>\n",
       "      <td>-4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>5.176004</td>\n",
       "      <td>1946.37</td>\n",
       "      <td>29.017971</td>\n",
       "      <td>-4.023996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.484465</td>\n",
       "      <td>1952.00</td>\n",
       "      <td>29.661152</td>\n",
       "      <td>-3.715535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4.715535</td>\n",
       "      <td>1906.37</td>\n",
       "      <td>27.982737</td>\n",
       "      <td>-4.484465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth     Mg/Ca     year  temperature      d18O\n",
       "0    0.5  5.023996  1981.30    28.686774 -4.176004\n",
       "1    1.0  5.100000  1961.30    28.853606 -4.100000\n",
       "2    1.5  5.176004  1946.37    29.017971 -4.023996\n",
       "3    2.0  5.484465  1952.00    29.661152 -3.715535\n",
       "4    2.5  4.715535  1906.37    27.982737 -4.484465"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tables = []\n",
    "\n",
    "for paleoData in ds.getPaleoData(): # loop over the various PaleoData objects\n",
    "    for table in paleoData.getMeasurementTables(): #get the measurement tables\n",
    "        df = table.getDataFrame(use_standard_names=True) # grab the data and standardize the variable names\n",
    "        data_tables.append(df)\n",
    "\n",
    "data_tables[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca282bc1-f1e4-41f7-ad31-5fad69ff5eb0",
   "metadata": {},
   "source": [
    "Let's have a look at the metadata for each variable (i.e., column), stored in the DataFrame attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2521716f-ea69-4c4b-a277-782e7e765d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': {'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-1e2a2-4620-480b-9ec6-674da.depth',\n",
       "  'interpretation': [{'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-1e2a2-4620-480b-9ec6-674da.depth.Interpretation1'}],\n",
       "  'archiveType': 'Marine sediment',\n",
       "  'number': 1,\n",
       "  'hasMaxValue': 23.0,\n",
       "  'hasMeanValue': 11.75,\n",
       "  'hasMedianValue': 10.75,\n",
       "  'hasMinValue': 0.5,\n",
       "  'variableName': 'depth',\n",
       "  'resolution': {'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-1e2a2-4620-480b-9ec6-674da.depth.Resolution',\n",
       "   'hasMaxValue': 66.52999999999997,\n",
       "   'hasMeanValue': 20.9051111111111,\n",
       "   'hasMedianValue': 3.1700000000000728,\n",
       "   'hasMinValue': 3.1699999999998454},\n",
       "  'hasStandardVariable': 'depth',\n",
       "  'units': 'cm',\n",
       "  'TSid': 'WEB-1e2a2-4620-480b-9ec6-674da',\n",
       "  'variableType': 'measured',\n",
       "  'proxyObservationType': 'depth'},\n",
       " 'Mg/Ca': {'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-c745d-99e8-4f77-9042-748f9.Mg_Ca',\n",
       "  'interpretation': [{'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-c745d-99e8-4f77-9042-748f9.Mg_Ca.Interpretation1',\n",
       "    'direction': 'positive',\n",
       "    'seasonality': 'Annual',\n",
       "    'variable': 'temperature',\n",
       "    'variableDetail': 'Sea surface'}],\n",
       "  'archiveType': 'Marine sediment',\n",
       "  'number': 3,\n",
       "  'description': 'Obtained from G.ruber',\n",
       "  'hasMaxValue': 5.797904362,\n",
       "  'hasMeanValue': 5.132975283934784,\n",
       "  'hasMedianValue': 5.118849202,\n",
       "  'hasMinValue': 4.402095638,\n",
       "  'variableName': 'Mg/Ca',\n",
       "  'proxy': 'Mg/Ca',\n",
       "  'resolution': {'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-c745d-99e8-4f77-9042-748f9.Mg_Ca.Resolution',\n",
       "   'hasMaxValue': 66.52999999999997,\n",
       "   'hasMeanValue': 20.9051111111111,\n",
       "   'hasMedianValue': 3.1700000000000728,\n",
       "   'hasMinValue': 3.1699999999998454},\n",
       "  'hasStandardVariable': 'Mg/Ca',\n",
       "  'units': 'permil',\n",
       "  'TSid': 'WEB-c745d-99e8-4f77-9042-748f9',\n",
       "  'variableType': 'measured',\n",
       "  'proxyObservationType': 'Mg/Ca'},\n",
       " 'year': {'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-e6f66-1365-427c-af34-363a2.year',\n",
       "  'interpretation': [{'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-e6f66-1365-427c-af34-363a2.year.Interpretation1'}],\n",
       "  'archiveType': 'Marine sediment',\n",
       "  'number': 2,\n",
       "  'hasMaxValue': 1981.3,\n",
       "  'hasMeanValue': 1572.5945652173914,\n",
       "  'hasMedianValue': 1568.7150000000001,\n",
       "  'hasMinValue': 1187.49,\n",
       "  'variableName': 'year',\n",
       "  'hasStandardVariable': 'year',\n",
       "  'units': 'yr AD',\n",
       "  'TSid': 'WEB-e6f66-1365-427c-af34-363a2',\n",
       "  'variableType': 'inferred',\n",
       "  'inferredVariableType': 'year'},\n",
       " 'temperature': {'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-5dd32-9b60-4662-9b73-ad1b3.temperature',\n",
       "  'interpretation': [{'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-5dd32-9b60-4662-9b73-ad1b3.temperature.Interpretation1'}],\n",
       "  'archiveType': 'Marine sediment',\n",
       "  'number': 5,\n",
       "  'hasMaxValue': 30.27867291,\n",
       "  'hasMeanValue': 28.91042688586957,\n",
       "  'hasMedianValue': 28.894521055,\n",
       "  'hasMinValue': 27.21849706,\n",
       "  'variableName': 'temperature',\n",
       "  'resolution': {'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-5dd32-9b60-4662-9b73-ad1b3.temperature.Resolution',\n",
       "   'hasMaxValue': 66.52999999999997,\n",
       "   'hasMeanValue': 20.9051111111111,\n",
       "   'hasMedianValue': 3.1700000000000728,\n",
       "   'hasMinValue': 3.1699999999998454},\n",
       "  'hasStandardVariable': 'temperature',\n",
       "  'units': 'degC',\n",
       "  'TSid': 'WEB-5dd32-9b60-4662-9b73-ad1b3',\n",
       "  'variableType': 'inferred',\n",
       "  'inferredVariableType': 'temperature',\n",
       "  'forTempAnalysis': True},\n",
       " 'd18O': {'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-f24e5-dcca-4743-b487-5c6fd.d18O',\n",
       "  'interpretation': [{'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-f24e5-dcca-4743-b487-5c6fd.d18O.Interpretation1'}],\n",
       "  'archiveType': 'Marine sediment',\n",
       "  'number': 4,\n",
       "  'hasMaxValue': -3.402095638,\n",
       "  'hasMeanValue': -4.067024716065219,\n",
       "  'hasMedianValue': -4.0811507979999995,\n",
       "  'hasMinValue': -4.797904362,\n",
       "  'variableName': 'd18O',\n",
       "  'proxy': 'd18O',\n",
       "  'resolution': {'@id': 'http://linked.earth/lipd/paleo0measurement0.WEB-f24e5-dcca-4743-b487-5c6fd.d18O.Resolution',\n",
       "   'hasMaxValue': 66.52999999999997,\n",
       "   'hasMeanValue': 20.9051111111111,\n",
       "   'hasMedianValue': 3.1700000000000728,\n",
       "   'hasMinValue': 3.1699999999998454},\n",
       "  'hasStandardVariable': 'd18O',\n",
       "  'units': 'permil',\n",
       "  'TSid': 'WEB-f24e5-dcca-4743-b487-5c6fd',\n",
       "  'variableType': 'measured',\n",
       "  'proxyObservationType': 'd18O'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tables[0].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7762665-cde7-476f-a274-fe487e1a1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "time  = data_tables[0]['year'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef0323-9b1a-4e51-aea9-9f56af22c076",
   "metadata": {},
   "source": [
    "Create 1000 realizations of the age ensemble by using a normal distribution centered around the `time` vector with a standard deviation of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58d946f7-a318-45cc-91ee-1671d1dffd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 5\n",
    "num_draws = 1000\n",
    "\n",
    "#Generate ensemble\n",
    "ens = np.random.normal(loc=time[:, np.newaxis], scale=std_dev, size=(len(time), num_draws))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d868c08-cb22-478c-9c01-8b1e67edc0fb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Make sure that the number of realization of the age ensembles correspond to the number of columns in your array\n",
    "</div>\n",
    "\n",
    "Next, let's inset the table into our dataset. First, let's check if there are any `ChronData` object we should attach the table to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e557a92-e3c4-4a4e-87d3-50fb9f71027d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.getChronData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1268a01-fa19-4039-afb1-700351b931a4",
   "metadata": {},
   "source": [
    "Since there are none, we will have to create a `ChronData` object in addition to a `Table` and `Model` object. Let's start with creating a `Table` object for the ensemble we have just created: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e86d7964-08e1-4b96-a599-ad37f54fa1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.classes.datatable import DataTable\n",
    "\n",
    "ensemble_table = DataTable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ae3fdb-09d4-42f0-af47-fe233c99ab73",
   "metadata": {},
   "source": [
    "To add content to our new `DataTable` object, the easiest way route is to use the [`setDataFrame`](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.datatable.DataTable.setDataFrame) method. To do so, we must first generate a DataFrame similar to the one we read in the [L3_dataset_class](L3_dataset_class.ipynb) notebook. In summary, the DataFrame contains two columns: one for depth and one for age, where the realizations are stored as a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae19beed-71a4-40c0-bfee-a1fd977314a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>[1974.619769613226, 1970.5808987987766, 1983.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[1961.8024862880193, 1958.780008195477, 1972.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>[1950.083766724935, 1947.7501498679933, 1943.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[1950.0940068843709, 1953.1629079500183, 1958....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>[1904.3071421579064, 1909.8852952646128, 1915....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth                                               year\n",
       "0    0.5  [1974.619769613226, 1970.5808987987766, 1983.7...\n",
       "1    1.0  [1961.8024862880193, 1958.780008195477, 1972.4...\n",
       "2    1.5  [1950.083766724935, 1947.7501498679933, 1943.7...\n",
       "3    2.0  [1950.0940068843709, 1953.1629079500183, 1958....\n",
       "4    2.5  [1904.3071421579064, 1909.8852952646128, 1915...."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize empty DataFrame with the depth column\n",
    "df_ens = pd.DataFrame({'depth': data_tables[0]['depth'].tolist()})\n",
    "\n",
    "# Add the year data - each row will contain one vector from array_data\n",
    "df_ens['year'] = [ens[i,:].tolist() for i in range(len(time))]\n",
    "\n",
    "df_ens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c199e28e-4f47-41c6-90c3-83010a9840a3",
   "metadata": {},
   "source": [
    "Add attributes to the Pandas Dataframe to store the metadata. \n",
    "\n",
    "<div style=\"color: white; background-color: #F9ACAA; border-left: 6px solid #CC0000; padding: 0.5em;\">\n",
    "    &#9888; <strong>Warning:</strong> Metadata attributes are necessary to save a LiPD file. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b59e6240-0922-4191-bdab-85d25c5f2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_year_columns = len(ens[0,:])\n",
    "year_columns = [i+2 for i in range(num_year_columns)]\n",
    "df_ens.attrs = {\n",
    "    'year': {'number': str(year_columns), 'variableName': 'year', 'units': 'yr AD', 'TSid':generate_unique_id()},\n",
    "    'depth': {'number': 1, 'variableName': 'depth', 'units': 'cm', 'TSid':generate_unique_id()}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b13cb-e61f-4e4a-9e9d-2323f8663078",
   "metadata": {},
   "source": [
    "Incorporate into the LiPD structure.\n",
    "\n",
    "<div style=\"color: white; background-color: #F9ACAA; border-left: 6px solid #CC0000; padding: 0.5em;\">\n",
    "    &#9888; <strong>Warning:</strong> Don't forget the set the name of the file for the table. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e74f8059-8d9a-459a-a9ae-9a5c52431c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_table.setDataFrame(df_ens)\n",
    "ensemble_table.setFileName(\"chron0model0ensemble0.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98210805-651a-4b21-98af-d8cecbf24c0c",
   "metadata": {},
   "source": [
    "Now add the table to a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01888658-0823-4b60-b352-aa563b02c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.classes.model import Model\n",
    "model = Model()\n",
    "model.addEnsembleTable(ensemble_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615c6832-d3c7-4908-9d0f-da80583b34bd",
   "metadata": {},
   "source": [
    "And add the Model to a ChronData object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d363aaf-baf2-4089-84a0-ae024db4cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.classes.chrondata import ChronData\n",
    "cd = ChronData()\n",
    "cd.addModeledBy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0121aa-10b2-46dd-9c37-acd5aa757b29",
   "metadata": {},
   "source": [
    "Finally add the ChronData to our Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d039243-02c9-4dbd-87ab-84d54bfe8aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.addChronData(cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f46c1-1102-4e59-a7e6-63862fc4a986",
   "metadata": {},
   "source": [
    "Voila! Let's check that we now have a ChronData object in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7cd38ec-fa8e-4138-b6da-671305f14f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pylipd.classes.chrondata.ChronData at 0x147116c10>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.getChronData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070d31df-9e10-47ee-8851-dc541620d4df",
   "metadata": {},
   "source": [
    "### Writing to a LiPD file\n",
    "\n",
    "The last step in this process is to write our edited file back into a LiPD file. To do so, you need to pass the Dataset `ds` back into a LiPD object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2d11a36-c1a8-4fbc-af5f-8896e494e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "lipd = LiPD()\n",
    "lipd.load_datasets([ds])\n",
    "lipd.create_lipd(ds.getName(), \"../data/MyWonderfulCorev2.LinkedEarth.2024.lpd\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177843ff-442b-47a7-aac1-314ed279854c",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Blaauw, M., & Christen, J. A. (2011). Flexible Paleoclimate Age-Depth Models using an Autoregressive Gamma Process. Bayesian Analysis, 6(3), 457-474.\n",
    "\n",
    "- Bronk Ramsey, C. (2008). Deposition models for chronological records, Quaternary Sci. Rev., 27, 42–60. \n",
    "\n",
    "- Haslett, J., & Parnell, A. (2008). A simple monotone process with application to radiocarbon-dated depth chronologies. Journal of the Royal Statistical Society C, 57, 399-418."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
