{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6680d928-fefa-4dfc-ae38-53aa2d29dda8",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/LinkedEarth/Logos/blob/master/PyLiPD/pyLiPD_logo1_transparent.png?raw=true\" width =\"800\">\n",
    "\n",
    "# Creating LiPD files from a tabular template\n",
    "\n",
    "## Authors\n",
    "\n",
    "[Deborah Khider](https://orcid.org/0000-0001-7501-8430)\n",
    "\n",
    "\n",
    "## Preamble\n",
    "\n",
    "If you are planning to only create one LiPD file on your own, we recommend using the [LiPD Playground](https://lipd.net/playground). This tutorial is intended for users who wish to programatically create multiple files from a template. \n",
    "\n",
    "In this example, we use [this templated file](https://github.com/LinkedEarth/pylipdTutorials/blob/main/data/Oman.Tian.2023.xlsx). You can repurpose the Excel template as needed; it is only meant as an example. \n",
    "\n",
    "### Goals\n",
    "\n",
    "* Create a LiPD formatted Dataset from an excel template\n",
    "* Adding an ensemble table \n",
    "* Save the Dataset to a file\n",
    "\n",
    "Reading Time: 20 minutes\n",
    "\n",
    "### Keywords\n",
    "\n",
    "LiPD, LinkedEarth Ontology, Object-Oriented Programming\n",
    "\n",
    "### Pre-requisites\n",
    "\n",
    "An understanding of OOP and the LinkedEarth Ontology. Completion of [Dataset class example](L3_dataset_class.ipynb). An understanding how to [edit LiPD files](L3_editing.ipynb) can also be useful.\n",
    "\n",
    "For reference, below is a diagram of the classed in PyliPD, the methods associated with them and the resulting objects:\n",
    "\n",
    "![image](https://github.com/LinkedEarth/pylipd/blob/main/examples/notebooks/UMLDiagram.png?raw=true)\n",
    "\n",
    "## Data Description\n",
    "\n",
    "- Tian, Y., Fleitmann, D., Zhang, Q., Sha, L., Wassenburg, J. A., Axelsson, J., … Cheng, H. (2023). Holocene climate change in southern Oman deciphered by speleothem records and climate model simulations. Nature Communications, 14(1), 4718. doi:[10.1038/s41467-023-40454-z](https://www.nature.com/articles/s41467-023-40454-z). \n",
    "\n",
    "## Demonstration\n",
    "\n",
    "Let's import the necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2583558-9d41-4f02-b4c3-441666dfd6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.classes.dataset import Dataset\n",
    "from pylipd.classes.archivetype import ArchiveTypeConstants\n",
    "from pylipd.classes.funding import Funding\n",
    "from pylipd.classes.interpretation import Interpretation\n",
    "from pylipd.classes.interpretationvariable import InterpretationVariableConstants\n",
    "from pylipd.classes.location import Location\n",
    "from pylipd.classes.paleodata import PaleoData\n",
    "from pylipd.classes.datatable import DataTable\n",
    "from pylipd.classes.paleounit import PaleoUnitConstants\n",
    "from pylipd.classes.paleovariable import PaleoVariableConstants\n",
    "from pylipd.classes.person import Person\n",
    "from pylipd.classes.publication import Publication\n",
    "from pylipd.classes.resolution import Resolution\n",
    "from pylipd.classes.variable import Variable\n",
    "from pylipd.classes.model import Model\n",
    "from pylipd.classes.chrondata import ChronData\n",
    "\n",
    "from pylipd import LiPD\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea7f60-a699-4698-a6da-71547688a095",
   "metadata": {},
   "source": [
    "### Opening our template file\n",
    "\n",
    "The Excel file contains the following sheets:\n",
    "- `About`\n",
    "- `Guidelines`\n",
    "- `Metadata`\n",
    "- `paleo1measurementTable1`\n",
    "- `chron1measurementTable1`\n",
    "- `Lists`\n",
    "\n",
    "The information we are interested in contained in `Metadata`, `paleo1measurementTable1` and `chron1measurementTable1`. Notice that the last two sheets follow the [LiPD nomenclature](https://lipd.net/playground) closely and this can be helpful to keep track of the tables and where to insert them. However, you may choose any names that is convenient for you. \n",
    "\n",
    "Let's start with the root metadata portion.\n",
    "\n",
    "### Metadata\n",
    "\n",
    "If you have a look at the Metadata sheet in the Excel file, you should notice that the information is orgnaized in four sections:\n",
    "* root metadata, which contains general information about the dataset such as its name and the type of archive the measurements were made on (e.g., coral, speleothem).\n",
    "* Publication information - Note that if more than one publication is associated with the dataset, then this information can be added in seperate columns. \n",
    "* Location information\n",
    "* Funding information\n",
    "\n",
    "The first step is to create a function to separate these different sections into four dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41bb1f05-59ac-4d28-a87a-8343f47169ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(df):\n",
    "    '''\n",
    "    Reads the inforamtion contained in the metadata sheet of the Excel template.\n",
    "    Note that the algorithm uses the blank lines in the template to denote the block (e.g., publication).\n",
    "\n",
    "    The code returns 4 pieces of information: root meatadata, location metadata, funding metadata, and publication metadata.\n",
    "    '''\n",
    "    # Check for empty rows across all columns\n",
    "    empty_rows = df.isnull().all(axis=1)\n",
    "    \n",
    "    # Initialize the start index of the first table\n",
    "    start_idx = 0\n",
    "    tables = []\n",
    "    \n",
    "    # Iterate through the indices of the DataFrame\n",
    "    for idx in empty_rows[empty_rows].index:\n",
    "        # Slice from the current start index to the row before the empty row\n",
    "        if not df[start_idx:idx].empty:\n",
    "            current_table = df[start_idx:idx]\n",
    "            # Check if the table should use its first row as header\n",
    "            if start_idx != 0:  # Skip header adjustment for the first table\n",
    "                current_table.columns = current_table.iloc[0]  # Set first row as header\n",
    "                current_table = current_table[1:]  # Remove the first row from the data\n",
    "                current_table.reset_index(drop=True, inplace=True)  # Reset index after dropping row\n",
    "            tables.append(current_table)\n",
    "        # Update start_idx to the row after the current empty row\n",
    "        start_idx = idx + 1\n",
    "    \n",
    "    # Handle the last table, if any, after the last empty row to the end of the DataFrame\n",
    "    if start_idx < len(df):\n",
    "        current_table = df[start_idx:]\n",
    "        if start_idx != 0:  # Likely unnecessary check but for consistency\n",
    "            current_table.columns = current_table.iloc[0]  # Set first row as header\n",
    "            current_table = current_table[1:]  # Remove the first row from the data\n",
    "            current_table.reset_index(drop=True, inplace=True)\n",
    "        tables.append(current_table)\n",
    "\n",
    "    # place the tables according to their types\n",
    "    root=tables[0]\n",
    "    pub=tables[1]\n",
    "    geo=tables[2]\n",
    "    fund=tables[3]\n",
    "\n",
    "    return root, pub, geo, fund    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7aef60-3dd9-4f3d-844c-3c01f15c2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/Oman.Tian.2023.xlsx\"\n",
    "sheet_name = 'Metadata'\n",
    "\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bece25be-7ad6-4d27-ac3d-663bd4aef875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the various tables\n",
    "root, pub, geo, fund = read_metadata(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478a182-083a-4e30-97f9-a7db0c3e70e1",
   "metadata": {},
   "source": [
    "The next step is to create an empty [`Dataset`](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.dataset.Dataset) object so we can start storing the information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf41a37-4a2e-47da-b460-24b4fc1fa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334bcd6f-5044-4ed1-9693-81fd03826366",
   "metadata": {},
   "source": [
    "Let's go over each of the information that we have stored in Pandas Dataframe, namely some root information such as the name of the dataset, geographical location, information about the source of funding, and publication(s) associated with the data. \n",
    "\n",
    "Let's start with the root information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a739f953-9896-4494-9d40-3073c5f9d34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset Name (siteName.firstAuthor.year)</td>\n",
       "      <td>Oman.Tian.2023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Archive Type</td>\n",
       "      <td>speleothem</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Original Source_URL (if applicable)</td>\n",
       "      <td>https://www.nature.com/articles/s41467-023-404...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investigators (Lastname, first; lastname2, fir...</td>\n",
       "      <td>Tian, Y., Fleitmann, D., Zhang, Q., Sha, L. J,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Unnamed: 0  \\\n",
       "0           Dataset Name (siteName.firstAuthor.year)   \n",
       "1                                       Archive Type   \n",
       "2                Original Source_URL (if applicable)   \n",
       "3  Investigators (Lastname, first; lastname2, fir...   \n",
       "\n",
       "                                          Unnamed: 1 Unnamed: 2  \n",
       "0                                     Oman.Tian.2023        NaN  \n",
       "1                                         speleothem        NaN  \n",
       "2  https://www.nature.com/articles/s41467-023-404...        NaN  \n",
       "3  Tian, Y., Fleitmann, D., Zhang, Q., Sha, L. J,...        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf596936-2859-471e-b577-59fb5f2e1ebb",
   "metadata": {},
   "source": [
    "Let's add this information to the `Dataset` object. You can see a list of possible properties under the [`Dataset` class in the documentation](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.dataset.Dataset). Remember from our previous tutorial that `set+PropertyName` is meant to create the information, which is what we will be doing here. If you cannot find you property in the list, don't panic! The LiPD format is flexible so you can add your own properties using the [`set_non_standard_property(key,value)` function](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.dataset.Dataset.set_non_standard_property). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce979af8-7a06-4424-9f03-def613e2bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.setName(root.iloc[0,1]) # set the name for the dataset\n",
    "ds.setArchiveType(root.iloc[1,1]) #set the archive type\n",
    "ds.setOriginalDataUrl(root.iloc[2,1]) # set the original data URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09994c7-1811-4f5b-82de-9ef17343811e",
   "metadata": {},
   "source": [
    "The next step is to enter the investigators, which takes a list of `Person` objects (see Figure in the Preamble): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f166950-75e9-4a0c-9b6d-1290354e3915",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = root.iloc[3,1]\n",
    "\n",
    "# Step 1: Split the string by commas\n",
    "parts = authors.split(',')\n",
    "\n",
    "# Prepare a list to hold the formatted names\n",
    "investigators = []\n",
    "\n",
    "# Step 2: Iterate over the parts to process each\n",
    "for i in range(0, len(parts) - 1, 2):  # Step by 2 since each name and initial are next to each other\n",
    "    last_name = parts[i].strip()  # Remove any leading/trailing whitespace\n",
    "    initial = parts[i + 1].strip()  # The initial follows the last name\n",
    "    person = Person() # create the Person object\n",
    "    person.setName(f\"{last_name}, {initial}\")\n",
    "    investigators.append(person)\n",
    "\n",
    "# Step 3: Store the list of Persons into the ds object\n",
    "ds.setInvestigators(investigators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a39eb-c483-437f-ad50-ecd1c0f5aa35",
   "metadata": {},
   "source": [
    "Let's have a quick look at what we've done so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6de8bec-ff9d-4384-bad8-c6e4edb31456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'speleothem'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.getArchiveType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "138f58c7-7c7b-4c67-895e-7be9352c63e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oman.Tian.2023'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.getName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79a5a30a-00ae-4898-8f62-2605e61f7f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tian, Y.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.getInvestigators()[0].getName() #get the name of the first person in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e345982a-2288-46fe-b172-c4bd2a6c4fd6",
   "metadata": {},
   "source": [
    "Everything looks good, let's move on to publication information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1ccb398-a1ea-4c8f-bbc8-38d44b6cebf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>5</th>\n",
       "      <th>Publication Section</th>\n",
       "      <th>Ref #1</th>\n",
       "      <th>Ref #2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Authors (last, first; last2, first2; separate ...</td>\n",
       "      <td>Tian, Y., Fleitmann, D., Zhang, Q., Sha, L. J,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Publication title</td>\n",
       "      <td>Holocene climate change in southern Oman decip...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Journal</td>\n",
       "      <td>Nature Communications</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Year</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Volume</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Issue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Report Number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DOI</td>\n",
       "      <td>10.1038/s41467-023-40454-z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abstract</td>\n",
       "      <td>Qunf Cave oxygen isotope (δ18Oc) record from s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alternate citation in paragraph format (For bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "5                                 Publication Section  \\\n",
       "0   Authors (last, first; last2, first2; separate ...   \n",
       "1                                   Publication title   \n",
       "2                                             Journal   \n",
       "3                                                Year   \n",
       "4                                              Volume   \n",
       "5                                               Issue   \n",
       "6                                               Pages   \n",
       "7                                       Report Number   \n",
       "8                                                 DOI   \n",
       "9                                            Abstract   \n",
       "10  Alternate citation in paragraph format (For bo...   \n",
       "\n",
       "5                                             Ref #1  Ref #2  \n",
       "0   Tian, Y., Fleitmann, D., Zhang, Q., Sha, L. J,...    NaN  \n",
       "1   Holocene climate change in southern Oman decip...    NaN  \n",
       "2                               Nature Communications    NaN  \n",
       "3                                                2023    NaN  \n",
       "4                                                 NaN    NaN  \n",
       "5                                                 NaN    NaN  \n",
       "6                                                 NaN    NaN  \n",
       "7                                                 NaN    NaN  \n",
       "8                          10.1038/s41467-023-40454-z    NaN  \n",
       "9   Qunf Cave oxygen isotope (δ18Oc) record from s...    NaN  \n",
       "10                                                NaN    NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3f097-31a6-4d1c-862a-01e60f179988",
   "metadata": {},
   "source": [
    "The first step is to create a [`Publication` object](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.publication.Publication). In this case, we only have one publication; otherwise you may need to loop over the various columns in the dataframe to create others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4b516e3-e7f4-4f11-a1c0-e757c44e5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub1 = Publication()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ac7a77-3ff9-47cc-828d-b2e06b303a7b",
   "metadata": {},
   "source": [
    "And now let's add the information. Let's start with the authors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80523c9f-5ffe-45bb-9063-7e96356971b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = pub.iloc[0,1]\n",
    "\n",
    "# Step 1: Split the string by commas\n",
    "parts = authors.split(',')\n",
    "\n",
    "# Prepare a list to hold the formatted names\n",
    "investigators = []\n",
    "\n",
    "# Step 2: Iterate over the parts to process each\n",
    "for i in range(0, len(parts) - 1, 2):  # Step by 2 since each name and initial are next to each other\n",
    "    last_name = parts[i].strip()  # Remove any leading/trailing whitespace\n",
    "    initial = parts[i + 1].strip()  # The initial follows the last name\n",
    "    person = Person() # create the Person object\n",
    "    person.setName(f\"{last_name}, {initial}\")\n",
    "    investigators.append(person)\n",
    "\n",
    "# Step 3: Store the list of Persons into the ds object\n",
    "pub1.setAuthors(investigators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfce393-b5a4-4c89-bb31-378ada81a265",
   "metadata": {},
   "source": [
    "Let's add other information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "088c420f-4549-42be-9849-02e2eda13070",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub1.setTitle(pub.iloc[1,1])\n",
    "pub1.setJournal(pub.iloc[2,1])\n",
    "pub1.setYear(pub.iloc[3,1])\n",
    "pub1.setDOI(pub.iloc[8,1])\n",
    "pub1.setAbstract(pub.iloc[9,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f4ccb-3de8-4c32-974d-03cf867970bb",
   "metadata": {},
   "source": [
    "Let's add our `Publication` object to the `Dataset` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71bc4205-9f09-4a8d-ba41-4f2573bc925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.addPublication(pub1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d74efb-5222-46eb-bf57-558ee7b3302b",
   "metadata": {},
   "source": [
    "Let's add geographical information next. First, we need to create a [`Location` object](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.location.Location):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f63e4e51-bf68-46b3-b36b-58ffe8dd2f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = Location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29763ff6-ec1a-4a63-9d68-fe4da739f6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>18</th>\n",
       "      <th>Site Information</th>\n",
       "      <th>Use appropriate significant digits for all values</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Northernmost latitude (decimal degree, South n...</td>\n",
       "      <td>17.17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Southernmost latitude (decimal degree, South n...</td>\n",
       "      <td>17.17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Easternmost longitude (decimal degree, West ne...</td>\n",
       "      <td>54.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Westernmost longitude (decimal degree, West ne...</td>\n",
       "      <td>54.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elevation (m), below sea level negative</td>\n",
       "      <td>650</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "18                                   Site Information  \\\n",
       "0   Northernmost latitude (decimal degree, South n...   \n",
       "1   Southernmost latitude (decimal degree, South n...   \n",
       "2   Easternmost longitude (decimal degree, West ne...   \n",
       "3   Westernmost longitude (decimal degree, West ne...   \n",
       "4             elevation (m), below sea level negative   \n",
       "\n",
       "18  Use appropriate significant digits for all values  NaN  \n",
       "0                                               17.17  NaN  \n",
       "1                                               17.17  NaN  \n",
       "2                                                54.3  NaN  \n",
       "3                                                54.3  NaN  \n",
       "4                                                 650  NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e22bef4-4c3d-4248-b882-292587d8c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc.setLatitude(geo.iloc[0,1])\n",
    "loc.setLongitude(geo.iloc[2,1])\n",
    "loc.setElevation(geo.iloc[4,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faff6e86-0de6-45f6-a8b7-eaba6032d696",
   "metadata": {},
   "source": [
    "Let's add the `Location` object into the `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "affb61d5-1b64-4ef0-a9be-89ddb8efcf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.setLocation(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235f1b08-297d-492c-9d31-865a746fcc9f",
   "metadata": {},
   "source": [
    "Finally, let's look at funding information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bf779ea-32e1-48c7-b56c-b24a2fd300b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>26</th>\n",
       "      <th>Funding_Agency</th>\n",
       "      <th>Any additional Funding agencies and grants should be entered in Columns C,D, etc.</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Funding_Agency_Name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Principal_Investigator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "26          Funding_Agency  \\\n",
       "0      Funding_Agency_Name   \n",
       "1                    Grant   \n",
       "2   Principal_Investigator   \n",
       "3                  country   \n",
       "\n",
       "26 Any additional Funding agencies and grants should be entered in Columns C,D, etc.   \\\n",
       "0                                                 NaN                                   \n",
       "1                                                 NaN                                   \n",
       "2                                                 NaN                                   \n",
       "3                                                 NaN                                   \n",
       "\n",
       "26  NaN  \n",
       "0   NaN  \n",
       "1   NaN  \n",
       "2   NaN  \n",
       "3   NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3783c254-7e64-4cb5-af35-1e90a65157fa",
   "metadata": {},
   "source": [
    "Since no information is available, let's move on to the PaleoData Section.\n",
    "\n",
    "### PaleoData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72871d71-a416-4679-a235-aafb869c215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name = 'paleo1measurementTable1'\n",
    "\n",
    "# Read the information into a Pandas DataFrame\n",
    "pd_df = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
    "\n",
    "# Drop completely empty rows\n",
    "pd_df = pd_df.dropna(how=\"all\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8323c3-c11d-4c3b-86b6-c9714fca273e",
   "metadata": {},
   "source": [
    "Let's create a [`PaleoData` object](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.paleodata.PaleoData):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "216bb4f7-eaff-42ac-88bc-aa0604c6bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "paleodata = PaleoData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523606f1-687f-4302-9d34-f8b6de553c18",
   "metadata": {},
   "source": [
    "Our next step is to create measurement tables in this object. To do so, we can use the [`DataTable` object](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.datatable.DataTable): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdb8c0d7-5432-4551-8aac-87afa170f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = DataTable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7e9780-b2fd-455e-9caa-cc3605034f48",
   "metadata": {},
   "source": [
    "Now let's add some information about the table such as the name and the value use for missin values in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6174fe5e-93c6-48da-84ff-2c651188b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.setFileName(\"paleo0measurement0.csv\")\n",
    "table.setMissingValue(\"NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2551f01-6a1a-4e7b-b392-5c9f60fe75b0",
   "metadata": {},
   "source": [
    "The next step is to add columns to our table. In other words, we need to create some variables.\n",
    "\n",
    "Let's have a look at the sheet in the excel file. It contains three sections:\n",
    "* Notes, which would be attached to the table\n",
    "* Variables information such as the name, units... Each row in the template represents metadata information for each of the column.\n",
    "* Data, which contains the numerical values for the variables.\n",
    "\n",
    "Let's first create an algorithm that separates the various section and returns the information in three dataframes (Notes, Variables, and Data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9357a40a-bc3e-48e1-be9e-61088faa9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(df): \n",
    "    '''\n",
    "    This function extracts the relevant sections for measurementTables. \n",
    "    '''\n",
    "    # Find the index positions of the section headers\n",
    "    notes_start = df[df[0] == \"Notes\"].index[0]\n",
    "    variables_start = df[df[0] == \"Variables\"].index[0]\n",
    "    data_start = df[df[0] == \"Data\"].index[0]\n",
    "\n",
    "    # Extract sections, ensuring blank rows are removed\n",
    "    df_notes = df.iloc[notes_start + 1:variables_start].dropna(how=\"all\").reset_index(drop=True)\n",
    "\n",
    "    # Extract the Variables section\n",
    "    df_variables_raw = df.iloc[variables_start + 1:data_start].dropna(how=\"all\").reset_index(drop=True)\n",
    "\n",
    "    # Set the first row as the header for the Variables section\n",
    "    df_variables = df_variables_raw[1:].reset_index(drop=True)  # Data rows\n",
    "    df_variables.columns = df_variables_raw.iloc[0]  # Set first row as column headers\n",
    "\n",
    "    # Extract the Data section\n",
    "    df_data_raw = df.iloc[data_start + 2:].dropna(how=\"all\").reset_index(drop=True)\n",
    "\n",
    "    # Correctly skip the first row and set the second row as the header\n",
    "    df_data = df_data_raw.iloc[1:].reset_index(drop=True)  # Skip first row, keep rest\n",
    "    df_data.columns = df_data_raw.iloc[0]  # Use second row as column headers\n",
    "    df_data = df_data.dropna(axis=1, how=\"all\") # Drop the columns with NaN.\n",
    "\n",
    "    return df_notes, df_variables, df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f51c521a-9d0b-405d-8bdf-cb7721377b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes, df_variables, df_data = extract_data(pd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7d526-981c-46eb-95a2-2502bd0596f6",
   "metadata": {},
   "source": [
    "Let's loop over the variables and get the relevant information. We will also be calculating some relevant information such as the average value and average resolution.\n",
    "\n",
    "In LiPD, each variable is also given a unique ID. The function below generates one: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4a1d46b-225a-4a16-9b92-b130dacdca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def generate_unique_id(prefix='PYD'):\n",
    "    # Generate a random UUID\n",
    "    random_uuid = uuid.uuid4()  # Generates a random UUID.\n",
    "    \n",
    "    # Convert UUID format to the specific format we need\n",
    "    # UUID is usually in the form '1e2a2846-2048-480b-9ec6-674daef472bd' so we slice and insert accordingly\n",
    "    id_str = str(random_uuid)\n",
    "    formatted_id = f\"{prefix}-{id_str[:5]}-{id_str[9:13]}-{id_str[14:18]}-{id_str[19:23]}-{id_str[24:28]}\"\n",
    "    \n",
    "    return formatted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bc988d2-22fb-41b6-a8d2-4cc9c809345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = []\n",
    "\n",
    "res = df_data.iloc[:, 1].diff()[1:].to_numpy()\n",
    "Res = Resolution() # create a Resolution object - it will be the same for all variables since it is based on time\n",
    "Res.setMinValue(np.min(res))\n",
    "Res.setMaxValue(np.max(res))\n",
    "Res.setMeanValue(np.mean(res))\n",
    "Res.setMedianValue(np.median(res))\n",
    "\n",
    "for index, row in df_variables.iterrows():\n",
    "    var = Variable()\n",
    "    var.setName(row['variableName']) # name of the variable\n",
    "    var.setColumnNumber(index+1) #The column in which the data is stored. Note that LiPD uses index 1\n",
    "    var.setVariableId(generate_unique_id(prefix='TIAN')) # create a unique ID for the variable\n",
    "    var.setUnits(row['Units'])\n",
    "    # Make sure the data is JSON writable (no numpy arrays or Pandas DataFrame)\n",
    "    var.setValues(json.dumps(df_data.iloc[:,index].tolist()))\n",
    "    # Calculate some metadata about the values - this makes it easier to do some queries later on, including looking for data in a particular time slice. \n",
    "    var.setMinValue(df_data.iloc[:,index].min())\n",
    "    var.setMaxValue(df_data.iloc[:,index].max())\n",
    "    var.setMeanValue(df_data.iloc[:,index].mean())\n",
    "    var.setMedianValue(df_data.iloc[:,index].median())\n",
    "    # Attach the resolution metadata information to the variable\n",
    "    var.setResolution(Res)\n",
    "    # append in the list\n",
    "    variables.append(var)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360b4cd-b0b8-49da-bb77-6492c62b8068",
   "metadata": {},
   "source": [
    "Let's now put our variables in the `DataTable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15293327-1ebc-4a84-8ac5-9e5fcb7ec330",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.setVariables(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8378eeaa-5db8-46dc-9aa5-c1ef64d33e12",
   "metadata": {},
   "source": [
    "The `Table` into the `PaleoData` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "320e7cc8-df59-43bf-95f8-a45f678aeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paleodata.setMeasurementTables([table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cb8e42-9879-46c2-b508-0c42dab6d529",
   "metadata": {},
   "source": [
    "And finally, the `PaleoData` object into the `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50787580-21dc-4edf-91d4-868a8d2742ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.addPaleoData(paleodata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c969a7-b5f3-44bb-a0c3-e0a257e49249",
   "metadata": {},
   "source": [
    "### ChronData\n",
    "\n",
    "The next step is to create a ChronData object to store the information about chronology. In the last section, we used an OOP approach to add the information about each variable. In this section, we will use an approach involving `Pandas DataFrame`.\n",
    "\n",
    "Let's open the data. The same function we wrote to read in the PaleoData can be used here since the template is the same for both objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "550e6e2e-2c98-40b1-83f9-5336aef3ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name = 'chron1measurementTable1'\n",
    "\n",
    "# Read the information into a Pandas DataFrame\n",
    "cd_df = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
    "\n",
    "# Drop completely empty rows\n",
    "cd_df = cd_df.dropna(how=\"all\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82844562-0174-4e50-973d-d7c9f52861bc",
   "metadata": {},
   "source": [
    "Let's create a [`ChronData` object](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.chrondata.ChronData):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "101120cf-1992-42b2-8a68-13e7843dcf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrondata = ChronData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524b922-144a-45cf-b5f3-2b4d2ef5732c",
   "metadata": {},
   "source": [
    "We need to create a `DataTable`, a process similar to what we have done for the PaleoData:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a0cc2b4-9ce9-4fc6-9680-9b29f29574e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrontable = DataTable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f57c62-3e38-4da2-bb2a-438b25755240",
   "metadata": {},
   "source": [
    "Let's add some basic information about the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f12d519e-be8e-4130-958b-e477616637d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrontable.setFileName(\"chron0measurement0.csv\")\n",
    "chrontable.setMissingValue(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ac29a54-db86-40d9-a056-9b91cf61cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc_notes, dfc_variables, dfc_data = extract_data(cd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203963b4-6f39-4526-a583-863505447112",
   "metadata": {},
   "source": [
    "We will used the [`setDataFrame` function](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.datatable.DataTable.setDataFrame) to incorporate the columns into the table. In this framework, the values are held in a dataframe (which is represented by `dfc_data` in our framework) and the metadata for each variable is added as attributes to the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae23656c-072b-4483-bb58-bbef568ae6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict = {} # create a dictionary\n",
    "\n",
    "for index, row in dfc_variables.iterrows():\n",
    "    temp_dict = {}\n",
    "    temp_dict['number']=index+1\n",
    "    temp_dict['variableName']=row['variableName']\n",
    "    temp_dict['TSid']= generate_unique_id(prefix='TC')\n",
    "    if pd.notna(row['Units']):\n",
    "        temp_dict['units']=row['Units']\n",
    "    else:\n",
    "        temp_dict['units']='NA'\n",
    "    try:\n",
    "        temp_dict['hasMinValue']=dfc_data.iloc[:,index].min()\n",
    "        temp_dict['hasMaxValue']=dfc_data.iloc[:,index].max()\n",
    "        temp_dict['hasMeanValue']=dfc_data.iloc[:,index].mean()\n",
    "        temp_dict['hasMedianValue']=dfc_data.iloc[:,index].median()\n",
    "    except:\n",
    "        pass      \n",
    "    metadata_dict[row['variableName']]=temp_dict\n",
    "\n",
    "dfc_data.attrs = metadata_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e87aca-e4b8-49d7-9a88-f1badbd2fd8d",
   "metadata": {},
   "source": [
    "Use the DataFrame to construct the `Table` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26e7f9da-6377-46d2-831a-d97cfa62e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrontable.setDataFrame(dfc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd1e274-f926-4c75-9135-cd5346077e01",
   "metadata": {},
   "source": [
    "Put the `Table` into the `ChronData` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e5e5bf4-97bf-47c1-9eb3-16549c1b9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrondata.setMeasurementTables([chrontable])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2216b9c0-f8a1-4bf5-b43e-8db620ddc076",
   "metadata": {},
   "source": [
    "Put the `ChronData` into the `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ebc1298-7350-4a5f-8a5f-2e58028277c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.addChronData(chrondata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601cb196-e0ce-4820-8f9c-6cf5dae16d82",
   "metadata": {},
   "source": [
    "#### Adding an ensemble table\n",
    "\n",
    "This particular dataset also has an ensemble table available in [Oman.Tian.2023.chrondf.csv](https://github.com/LinkedEarth/pylipdTutorials/raw/refs/heads/main/data/Oman.Tian.2023.chrondf.csv). Let's add the information to an ensembleTable in the LiPD file.\n",
    "\n",
    "Let's first open the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6d650dd-430d-4eb5-805f-c3e045118a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>d18O</th>\n",
       "      <th>depth</th>\n",
       "      <th>chron_0</th>\n",
       "      <th>chron_1</th>\n",
       "      <th>chron_2</th>\n",
       "      <th>chron_3</th>\n",
       "      <th>chron_4</th>\n",
       "      <th>chron_5</th>\n",
       "      <th>...</th>\n",
       "      <th>chron_990</th>\n",
       "      <th>chron_991</th>\n",
       "      <th>chron_992</th>\n",
       "      <th>chron_993</th>\n",
       "      <th>chron_994</th>\n",
       "      <th>chron_995</th>\n",
       "      <th>chron_996</th>\n",
       "      <th>chron_997</th>\n",
       "      <th>chron_998</th>\n",
       "      <th>chron_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>401.88</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>444.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>...</td>\n",
       "      <td>430.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>408.55</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>445.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>...</td>\n",
       "      <td>431.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>424.07</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>1.37</td>\n",
       "      <td>489.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>...</td>\n",
       "      <td>469.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>438.75</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>2.06</td>\n",
       "      <td>562.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>524.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>450.24</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>568.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>...</td>\n",
       "      <td>547.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     age  d18O  depth  chron_0  chron_1  chron_2  chron_3  \\\n",
       "0           0  401.88 -0.20   0.00    444.0    445.0    417.0    290.0   \n",
       "1           1  408.55 -0.59   0.69    445.0    446.0    445.0    355.0   \n",
       "2           2  424.07 -0.58   1.37    489.0    491.0    482.0    425.0   \n",
       "3           3  438.75 -0.73   2.06    562.0    568.0    525.0    495.0   \n",
       "4           4  450.24 -1.26   2.75    568.0    574.0    536.0    503.0   \n",
       "\n",
       "   chron_4  chron_5  ...  chron_990  chron_991  chron_992  chron_993  \\\n",
       "0    403.0    349.0  ...      430.0      407.0      410.0      369.0   \n",
       "1    404.0    367.0  ...      431.0      410.0      411.0      371.0   \n",
       "2    448.0    422.0  ...      469.0      468.0      459.0      411.0   \n",
       "3    521.0    504.0  ...      533.0      565.0      541.0      479.0   \n",
       "4    531.0    514.0  ...      547.0      575.0      548.0      491.0   \n",
       "\n",
       "   chron_994  chron_995  chron_996  chron_997  chron_998  chron_999  \n",
       "0      392.0      347.0      359.0      416.0      414.0      408.0  \n",
       "1      395.0      358.0      362.0      417.0      416.0      414.0  \n",
       "2      437.0      397.0      422.0      441.0      463.0      435.0  \n",
       "3      507.0      455.0      524.0      482.0      541.0      466.0  \n",
       "4      510.0      461.0      530.0      493.0      549.0      480.0  \n",
       "\n",
       "[5 rows x 1004 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_path = \"../data/Oman.Tian.2023.chrondf.csv\"\n",
    "\n",
    "df_ens = pd.read_csv(ens_path)\n",
    "df_ens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc283b-9209-487b-a5eb-ca340f6470b5",
   "metadata": {},
   "source": [
    "<div style=\"color: white; background-color: #F9ACAA; border-left: 6px solid #CC0000; padding: 0.5em;\">\n",
    "    &#9888; <strong>Warning:</strong> LiPD files require ensemble tables to have the following format: the first column contains depth and the other column the ensemble members as a list. \n",
    "</div>\n",
    "\n",
    "Our first step is to drop the first 3 columns in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67aeee84-51d3-403d-b754-cd6e4da4a0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>chron_0</th>\n",
       "      <th>chron_1</th>\n",
       "      <th>chron_2</th>\n",
       "      <th>chron_3</th>\n",
       "      <th>chron_4</th>\n",
       "      <th>chron_5</th>\n",
       "      <th>chron_6</th>\n",
       "      <th>chron_7</th>\n",
       "      <th>chron_8</th>\n",
       "      <th>...</th>\n",
       "      <th>chron_990</th>\n",
       "      <th>chron_991</th>\n",
       "      <th>chron_992</th>\n",
       "      <th>chron_993</th>\n",
       "      <th>chron_994</th>\n",
       "      <th>chron_995</th>\n",
       "      <th>chron_996</th>\n",
       "      <th>chron_997</th>\n",
       "      <th>chron_998</th>\n",
       "      <th>chron_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>444.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>...</td>\n",
       "      <td>430.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.69</td>\n",
       "      <td>445.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>...</td>\n",
       "      <td>431.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.37</td>\n",
       "      <td>489.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>...</td>\n",
       "      <td>469.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.06</td>\n",
       "      <td>562.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>524.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.75</td>\n",
       "      <td>568.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>...</td>\n",
       "      <td>547.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth  chron_0  chron_1  chron_2  chron_3  chron_4  chron_5  chron_6  \\\n",
       "0   0.00    444.0    445.0    417.0    290.0    403.0    349.0    387.0   \n",
       "1   0.69    445.0    446.0    445.0    355.0    404.0    367.0    405.0   \n",
       "2   1.37    489.0    491.0    482.0    425.0    448.0    422.0    447.0   \n",
       "3   2.06    562.0    568.0    525.0    495.0    521.0    504.0    506.0   \n",
       "4   2.75    568.0    574.0    536.0    503.0    531.0    514.0    511.0   \n",
       "\n",
       "   chron_7  chron_8  ...  chron_990  chron_991  chron_992  chron_993  \\\n",
       "0    412.0    341.0  ...      430.0      407.0      410.0      369.0   \n",
       "1    413.0    369.0  ...      431.0      410.0      411.0      371.0   \n",
       "2    442.0    441.0  ...      469.0      468.0      459.0      411.0   \n",
       "3    492.0    543.0  ...      533.0      565.0      541.0      479.0   \n",
       "4    501.0    555.0  ...      547.0      575.0      548.0      491.0   \n",
       "\n",
       "   chron_994  chron_995  chron_996  chron_997  chron_998  chron_999  \n",
       "0      392.0      347.0      359.0      416.0      414.0      408.0  \n",
       "1      395.0      358.0      362.0      417.0      416.0      414.0  \n",
       "2      437.0      397.0      422.0      441.0      463.0      435.0  \n",
       "3      507.0      455.0      524.0      482.0      541.0      466.0  \n",
       "4      510.0      461.0      530.0      493.0      549.0      480.0  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens = df_ens.iloc[:, 3:]\n",
    "df_ens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e9ed8-229f-49ad-9b73-afd0127e16f9",
   "metadata": {},
   "source": [
    "Next, let's create the proper dataframe format. The first column will stay the same. The second column will contain each values on the ensemble in a list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe7fe239-e045-4194-8570-2424c6b30704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>[444.0, 445.0, 417.0, 290.0, 403.0, 349.0, 387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.69</td>\n",
       "      <td>[445.0, 446.0, 445.0, 355.0, 404.0, 367.0, 405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.37</td>\n",
       "      <td>[489.0, 491.0, 482.0, 425.0, 448.0, 422.0, 447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.06</td>\n",
       "      <td>[562.0, 568.0, 525.0, 495.0, 521.0, 504.0, 506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.75</td>\n",
       "      <td>[568.0, 574.0, 536.0, 503.0, 531.0, 514.0, 511...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth                                               year\n",
       "0   0.00  [444.0, 445.0, 417.0, 290.0, 403.0, 349.0, 387...\n",
       "1   0.69  [445.0, 446.0, 445.0, 355.0, 404.0, 367.0, 405...\n",
       "2   1.37  [489.0, 491.0, 482.0, 425.0, 448.0, 422.0, 447...\n",
       "3   2.06  [562.0, 568.0, 525.0, 495.0, 521.0, 504.0, 506...\n",
       "4   2.75  [568.0, 574.0, 536.0, 503.0, 531.0, 514.0, 511..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's keep the first column (depth) in place\n",
    "ens_table = pd.DataFrame({'depth': df_ens['depth'].tolist()})\n",
    "\n",
    "# Add the year data - each row will contain one vector from a data array. \n",
    "array = df_ens.iloc[:, 1:].to_numpy()\n",
    "ens_table['year'] = [array[i,:].tolist() for i in range(array.shape[0])]\n",
    "ens_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c92b55-3097-4a01-a041-9db76b57a99e",
   "metadata": {},
   "source": [
    "Add attributes to the Pandas Dataframe to store the metadata. \n",
    "\n",
    "<div style=\"color: white; background-color: #F9ACAA; border-left: 6px solid #CC0000; padding: 0.5em;\">\n",
    "    &#9888; <strong>Warning:</strong> Metadata attributes are necessary to save a LiPD file. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07f6372b-aa23-4eb0-9877-e63cd5f3fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_year_columns = len(array[0,:])\n",
    "year_columns = [i+2 for i in range(num_year_columns)]\n",
    "ens_table.attrs = {\n",
    "    'year': {'number': str(year_columns), 'variableName': 'year', 'units': 'yr AD', 'TSid':generate_unique_id()},\n",
    "    'depth': {'number': 1, 'variableName': 'depth', 'units': 'cm', 'TSid':generate_unique_id()}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f268220-813e-4509-929d-cc14cc6302b4",
   "metadata": {},
   "source": [
    "Let's create a `DataTable` object for our ensemble table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f0ca108-352d-4df7-92e4-0ae3bf657fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_table = DataTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33a5beeb-f74f-407f-8c49-6dff5487387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_table.setDataFrame(ens_table)\n",
    "ensemble_table.setFileName(\"chron0model0ensemble0.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c37674-f6d3-4f23-be10-832c5f33c6b6",
   "metadata": {},
   "source": [
    "Now add the table to a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eee2c51f-720e-43f1-926c-f342e0fdb230",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.addEnsembleTable(ensemble_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc02f6-06e4-41a3-8b53-9ad55e720c51",
   "metadata": {},
   "source": [
    "And add the Model to a ChronData object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3936363d-02d6-4c0e-9557-78e68e84aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrondata.addModeledBy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a9f1f-8a47-48c7-a934-2541d3a331d3",
   "metadata": {},
   "source": [
    "### Writing a LiPD file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16acf78b-2a68-4edb-b707-4acb24c3a19e",
   "metadata": {},
   "source": [
    "The last step in this process is to write to a LiPD file. To do so, you need to pass the Dataset `ds` back into a LiPD object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd560c4c-8a71-4e52-8f6a-5f3b50ae580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lipd = LiPD()\n",
    "lipd.load_datasets([ds])\n",
    "lipd.create_lipd(ds.getName(), \"../data/Oman.Tian.2023.lpd\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205736d2-d722-46fd-b9a4-3d7bcb3f6bbb",
   "metadata": {},
   "source": [
    "### Opening the LiPD file\n",
    "\n",
    "Let's re-open the LiPD file that we have just created and check some of our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9093e13c-f14e-4f41-9147-49137a7442da",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'getPaleoData'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m L \u001b[38;5;241m=\u001b[39m LiPD()\n\u001b[1;32m      2\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/Oman.Tian.2023.lpd\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/pylipd/pylipd/lipd.py:1350\u001b[0m, in \u001b[0;36mLiPD.load_datasets\u001b[0;34m(self, datasets)\u001b[0m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;124;03mLoads instances of Dataset class into the LiPD graph\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m-> 1350\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fix_missing_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1351\u001b[0m     dsuri \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mid\n\u001b[1;32m   1352\u001b[0m     j2r \u001b[38;5;241m=\u001b[39m JSONToRDF(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph, dsuri)\n",
      "File \u001b[0;32m~/Documents/GitHub/pylipd/pylipd/lipd.py:1286\u001b[0m, in \u001b[0;36mLiPD._fix_missing_ids\u001b[0;34m(self, ds)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fix_missing_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m, ds: Dataset):\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;66;03m# Assign variable ids if not present\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;66;03m# Assign datatable csv file name if not present\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m     pd_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1286\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pd \u001b[38;5;129;01min\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetPaleoData\u001b[49m():\n\u001b[1;32m   1287\u001b[0m         table_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mgetMeasurementTables():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'getPaleoData'"
     ]
    }
   ],
   "source": [
    "L = LiPD()\n",
    "file = \"../data/Oman.Tian.2023.lpd\"\n",
    "\n",
    "L.load_datasets(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86acf0-4d53-4f90-a3ff-383a8b1dbaef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
