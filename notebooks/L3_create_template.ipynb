{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6680d928-fefa-4dfc-ae38-53aa2d29dda8",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/LinkedEarth/Logos/blob/master/PyLiPD/pyLiPD_logo1_transparent.png?raw=true\" width =\"800\">\n",
    "\n",
    "# Creating LiPD files from a tabular template\n",
    "\n",
    "## Authors\n",
    "\n",
    "[Deborah Khider](https://orcid.org/0000-0001-7501-8430)\n",
    "\n",
    "\n",
    "## Preamble\n",
    "\n",
    "If you are planning to only create one LiPD file on your own, we recommend using the [LiPD Playground](https://lipd.net/playground). This tutorial is intended for users who wish to programatically create multiple files from a template. \n",
    "\n",
    "In this example, we use [this templated file](https://github.com/LinkedEarth/pylipdTutorials/blob/main/data/Oman.Tian.2023.xlsx).You can repurpose the Excel template as needed; it is only meant as an example. \n",
    "\n",
    "### Goals\n",
    "\n",
    "* Create a LiPD formatted Dataset from an excel template\n",
    "* Adding an ensemble table \n",
    "* Save the Dataset to a file\n",
    "\n",
    "Reading Time: 10 minutes\n",
    "\n",
    "### Keywords\n",
    "\n",
    "LiPD, LinkedEarth Ontology, Object-Oriented Programming\n",
    "\n",
    "### Pre-requisites\n",
    "\n",
    "An understanding of OOP and the LinkedEarth Ontology. Completion of [Dataset class example](L3_dataset_class.ipynb). An understanding how to [edit LiPD files](L3_editing.ipynb) can also be useful. \n",
    "\n",
    "## Data Description\n",
    "\n",
    "- Tian, Y., Fleitmann, D., Zhang, Q., Sha, L., Wassenburg, J. A., Axelsson, J., â€¦ Cheng, H. (2023). Holocene climate change in southern Oman deciphered by speleothem records and climate model simulations. Nature Communications, 14(1), 4718. doi:[10.1038/s41467-023-40454-z](https://www.nature.com/articles/s41467-023-40454-z). \n",
    "\n",
    "## Demonstration\n",
    "\n",
    "Let's import the necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2583558-9d41-4f02-b4c3-441666dfd6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.classes.dataset import Dataset\n",
    "from pylipd.classes.archivetype import ArchiveTypeConstants\n",
    "from pylipd.classes.funding import Funding\n",
    "from pylipd.classes.interpretation import Interpretation\n",
    "from pylipd.classes.interpretationvariable import InterpretationVariableConstants\n",
    "from pylipd.classes.location import Location\n",
    "from pylipd.classes.paleodata import PaleoData\n",
    "from pylipd.classes.datatable import DataTable\n",
    "from pylipd.classes.paleounit import PaleoUnitConstants\n",
    "from pylipd.classes.paleovariable import PaleoVariableConstants\n",
    "from pylipd.classes.person import Person\n",
    "from pylipd.classes.publication import Publication\n",
    "from pylipd.classes.resolution import Resolution\n",
    "from pylipd.classes.variable import Variable\n",
    "from pylipd.classes.model import Model\n",
    "from pylipd.classes.chrondata import ChronData\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea7f60-a699-4698-a6da-71547688a095",
   "metadata": {},
   "source": [
    "### Opening our template file\n",
    "\n",
    "The Excel file contains the following sheets:\n",
    "- `About`\n",
    "- `Guidelines`\n",
    "- `Metadata`\n",
    "- `paleo1measurementTable1`\n",
    "- `chron1measurementTable1`\n",
    "- `Lists`\n",
    "\n",
    "The information we are interested in contained in `Metadata`, `paleo1measurementTable1` and `chron1measurementTable1`. Notice that the last two sheets follow the [LiPD nomenclature](https://lipd.net/playground) closely and this can be helpful to keep track of the tables and where to insert them. However, you may choose any names that is convenient for you. \n",
    "\n",
    "Let's start with the root metadata portion.\n",
    "\n",
    "#### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41bb1f05-59ac-4d28-a87a-8343f47169ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(df):\n",
    "    # Check for empty rows across all columns\n",
    "    empty_rows = df.isnull().all(axis=1)\n",
    "    \n",
    "    # Initialize the start index of the first table\n",
    "    start_idx = 0\n",
    "    tables = []\n",
    "    \n",
    "    # Iterate through the indices of the DataFrame\n",
    "    for idx in empty_rows[empty_rows].index:\n",
    "        # Slice from the current start index to the row before the empty row\n",
    "        if not df[start_idx:idx].empty:\n",
    "            current_table = df[start_idx:idx]\n",
    "            # Check if the table should use its first row as header\n",
    "            if start_idx != 0:  # Skip header adjustment for the first table\n",
    "                current_table.columns = current_table.iloc[0]  # Set first row as header\n",
    "                current_table = current_table[1:]  # Remove the first row from the data\n",
    "                current_table.reset_index(drop=True, inplace=True)  # Reset index after dropping row\n",
    "            tables.append(current_table)\n",
    "        # Update start_idx to the row after the current empty row\n",
    "        start_idx = idx + 1\n",
    "    \n",
    "    # Handle the last table, if any, after the last empty row to the end of the DataFrame\n",
    "    if start_idx < len(df):\n",
    "        current_table = df[start_idx:]\n",
    "        if start_idx != 0:  # Likely unnecessary check but for consistency\n",
    "            current_table.columns = current_table.iloc[0]  # Set first row as header\n",
    "            current_table = current_table[1:]  # Remove the first row from the data\n",
    "            current_table.reset_index(drop=True, inplace=True)\n",
    "        tables.append(current_table)\n",
    "\n",
    "    # place the tables according to their types\n",
    "    root=tables[0]\n",
    "    pub=tables[1]\n",
    "    geo=tables[2]\n",
    "    fund=tables[3]\n",
    "\n",
    "    return root, pub, geo, fund    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a7aef60-3dd9-4f3d-844c-3c01f15c2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/Oman.Tian.2023.xlsx\"\n",
    "sheet_name = 'Metadata'\n",
    "\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bece25be-7ad6-4d27-ac3d-663bd4aef875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the various tables\n",
    "root, pub, geo, fund = read_metadata(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478a182-083a-4e30-97f9-a7db0c3e70e1",
   "metadata": {},
   "source": [
    "The next step is to create an empty [`Dataset`](https://pylipd.readthedocs.io/en/latest/api.html#pylipd.classes.dataset.Dataset) object so we can start storing the information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf41a37-4a2e-47da-b460-24b4fc1fa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
