{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "038ef1b4-5e42-41d1-a4a3-e3f66eb18bc8",
   "metadata": {},
   "source": [
    "# Custom queries on LiPD objects\n",
    "\n",
    "## Authors\n",
    "\n",
    "[Deborah Khider](https://orcid.org/0000-0001-7501-8430)\n",
    "\n",
    "## Preamble\n",
    "\n",
    "`PyLiPD` is a Python package that allows you to read, manipulate, and write [LiPD](https://cp.copernicus.org/articles/12/1093/2016/cp-12-1093-2016-discussion.html#discussion) formatted datasets. In this tutorial, we will demonstrate how to generate your custom queries. \n",
    "\n",
    "### Goals\n",
    "\n",
    "* Learn how to build SPAQRL queries\n",
    "\n",
    "Reading Time: 5 minutes\n",
    "\n",
    "### Keywords\n",
    "\n",
    "LiPD, SPARQL\n",
    "\n",
    "### Pre-requisites\n",
    "\n",
    "* [Understand the basics of RDF and SPAQRL](http://linked.earth/pylipdTutorials/graph.html)\n",
    "* [Loading LiPD objects](L0_loading_lips_datasets.md)\n",
    "* [Getting information from LiPD objects](L1_getting_information.md)\n",
    "* [Filtering by certain criteria](L1_filtering.md)                                                                                   \n",
    "                                                                                \n",
    "### Relevant Packages\n",
    "\n",
    "pylipd\n",
    "\n",
    "## Data Description\n",
    "\n",
    "This notebook uses the following datasets, in LiPD format:\n",
    "\n",
    "- McCabe-Glynn, S., Johnson, K., Strong, C. et al. Variable North Pacific influence on drought in southwestern North America since AD 854. Nature Geosci 6, 617–621 (2013). https://doi.org/10.1038/ngeo1862\n",
    "\n",
    "- Lawrence, K. T., Liu, Z. H., & Herbert, T. D. (2006). Evolution of the eastern tropical Pacific through Plio-Pleistocne glaciation. Science, 312(5770), 79-83.\n",
    "\n",
    "- PAGES2k Consortium., Emile-Geay, J., McKay, N. et al. A global multiproxy database for temperature reconstructions of the Common Era. Sci Data 4, 170088 (2017). doi:10.1038/sdata.2017.88\n",
    "\n",
    "## Demonstration\n",
    "\n",
    "### Understanding the LiPD object\n",
    "\n",
    "Let's start by importing our favorite package and load our datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22ba81b-35e3-4d3a-9158-8722393541fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylipd.lipd import LiPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbec05c0-837e-4417-a80b-cbf172eae6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 16 LiPD files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 37.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = '../data/Pages2k/'\n",
    "\n",
    "D = LiPD()\n",
    "D.load_from_dir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410c066a-775f-41de-9b31-bc2a5707f1ef",
   "metadata": {},
   "source": [
    "By now, you should be familiar with our `load` functionalities. But you need to understand a little bit about what's happening under the hood to truly appreciate this tutorial and why everything will function the way it does. \n",
    "\n",
    "- The first step is to expand the dataset stored in LiPD format. Remember that LiPD essentially consists of data tables stored in csv format and a JSON-LD file that contains the metadata.\n",
    "- The second step is to map the JSON file to RDF using our ontology as the schema.\n",
    "- The third (and **unique**) step is to load the data contained into the csv files into the graph directly. This is quite unique to LinkedEarth. If you work with other knowledge bases, you'll find that most of the time, the actual data are stored in another format that you will need the learn to handle in conjunction with the metadata.\n",
    "\n",
    "Also, each dataset gets its own graph! So you can think of the `LiPD` object as a collection of graphs, each of which represent a particular dataset. \n",
    "\n",
    "Let's have a close look at our object, shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697b437f-1149-4a05-bd57-116f07d6dfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graph': <Graph identifier=Ned1080da185c444fa3d3836b882df696 (<class 'rdflib.graph.ConjunctiveGraph'>)>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.copy().__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2513e63-5b13-4a57-bc8e-3cfb499c5b93",
   "metadata": {},
   "source": [
    "In particular, our graph object is a `ConjuctiveGraph` from the [rdflib library](https://rdflib.readthedocs.io/en/stable/). Why should you care?\n",
    "\n",
    "1. If you isolate the graph, then you can use the `rdflib` package directly. Since this is a well-maintained community package with a larger user base than `PyLiPD`, chances are that stackoverflow or their documentation will provide you with some answers on how to work with your graph.\n",
    "2. why a `ConjuctiveGraph`? We use this particular type because although each dataset is stored into its own graph, we often want to query across datasets (i.e., across graphs) and this particular object in `rdflib` allows us to do so.\n",
    "\n",
    "Ok, so let's try to create our own queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b57e86-b972-45f4-a003-1722666ef486",
   "metadata": {},
   "source": [
    "### Constructing a query\n",
    "\n",
    "Let's return to the query described in [this primer](http://linked.earth/pylipdTutorials/graph.html) in which we try to gather all the dataset names. Let's modify it to also return the variable `ds` so you can see the difference between the object and the name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "916a104b-9c6a-4711-b2aa-284a80db4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"\n",
    "\n",
    "PREFIX le:<http://linked.earth/ontology#>\n",
    "\n",
    "SELECT ?ds ?dsname WHERE{\n",
    "\n",
    "?ds a le:Dataset .\n",
    "?ds le:name ?dsname .}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e0cc0-5822-418d-8c61-431e1cd3688d",
   "metadata": {},
   "source": [
    "Notice that this is just a string containing the query in SPARQL language. Now, let's perform it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38280626-1649-4e65-8058-6e34929604fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, res_df = D.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48054f23-1692-484f-95d6-d148beee88cf",
   "metadata": {},
   "source": [
    "Which returns two objects:\n",
    "* res, which is a `SPARQLResult` object from `rdflib`\n",
    "* res_df, which processes the `SPARQLResult` into a DataFrame, which is often what you will be interested to look at. Let's have a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6230759e-46d0-41e7-bb16-bc25a2b9a299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>dsname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://linked.earth/lipd/Ocn-RedSea.Felis.2000</td>\n",
       "      <td>Ocn-RedSea.Felis.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://linked.earth/lipd/Ant-WAIS-Divide.Sever...</td>\n",
       "      <td>Ant-WAIS-Divide.Severinghaus.2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://linked.earth/lipd/Asi-SourthAndMiddleUr...</td>\n",
       "      <td>Asi-SourthAndMiddleUrals.Demezhko.2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://linked.earth/lipd/Ocn-AlboranSea436B.Ni...</td>\n",
       "      <td>Ocn-AlboranSea436B.Nieto-Moreno.2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://linked.earth/lipd/Eur-SpannagelCave.Man...</td>\n",
       "      <td>Eur-SpannagelCave.Mangini.2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ds  \\\n",
       "0     http://linked.earth/lipd/Ocn-RedSea.Felis.2000   \n",
       "1  http://linked.earth/lipd/Ant-WAIS-Divide.Sever...   \n",
       "2  http://linked.earth/lipd/Asi-SourthAndMiddleUr...   \n",
       "3  http://linked.earth/lipd/Ocn-AlboranSea436B.Ni...   \n",
       "4  http://linked.earth/lipd/Eur-SpannagelCave.Man...   \n",
       "\n",
       "                                   dsname  \n",
       "0                   Ocn-RedSea.Felis.2000  \n",
       "1       Ant-WAIS-Divide.Severinghaus.2012  \n",
       "2  Asi-SourthAndMiddleUrals.Demezhko.2007  \n",
       "3    Ocn-AlboranSea436B.Nieto-Moreno.2013  \n",
       "4          Eur-SpannagelCave.Mangini.2005  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5de1b-1987-4a16-a939-ccd61b28760d",
   "metadata": {},
   "source": [
    "First, notice that the columns of the dataframe corresponds to the names of the variables that you have specified in the SPARQL query. You can choose any name that you want as long as you use a question mark at the beginning to indicate to SPARQL that you are questioning the database for the answer. Second notice the difference between `ds` and `dsname`. `ds` is the dataset object and the query returns the URI of that object. `dsname` is a string, which contains the names of the dataset. In general, we form our URIs with the names of the objects so don't be surprised if you sometimes end up with the URI instead of the name (we all sometimes forget to ask for the name)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b0201-f83f-4247-8783-d2fe544043f5",
   "metadata": {},
   "source": [
    "One thing to consider is the speed of query. If you're doing exploratory work with SPARQL, you may wish to only return a few results to see if you're doing this right. In this case, the number of datasets is quite small:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a42aa7bc-8e4e-4f53-ba86-f075fcdf9bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510cfeb-217b-4d8b-b6b5-996afa7af157",
   "metadata": {},
   "source": [
    "But if you have thousands of rows in that dataframe, you might not want to wait for the query to perform as this may take a few minutes. If you only want to return the first 10 rows in the query, just add the limit to the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3968b39c-7bdf-4c83-a379-19e4467ef4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query =\"\"\"\n",
    "\n",
    "PREFIX le:<http://linked.earth/ontology#>\n",
    "\n",
    "SELECT ?ds ?dsname WHERE{\n",
    "\n",
    "?ds a le:Dataset .\n",
    "?ds le:name ?dsname .}\n",
    "\n",
    "LIMIT 10\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "res, res_df = D.query(query)\n",
    "\n",
    "len(res_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73febb-d33d-40fd-86a5-c6db12dd05f0",
   "metadata": {},
   "source": [
    "Please note that the number of rows doesn't correspond to the number of datasets. For instance, if I ask for each variable in a dataset, then each variable will be contained in an individual row. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e7442e-0d2a-4c96-be58-39792d4dbf6e",
   "metadata": {},
   "source": [
    "### Optional variables\n",
    "\n",
    "Let's pop out one the Pages2k dataset into a new LiPD object, `D2` and add the ODP846 dataset for the purpose of this demonstration. Why ODP846? The file was created before LiPD had DatasetIDs, therefore I know this dataset doesn't have one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "446082c8-14d6-4e04-8613-8f6801de6d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ocn-RedSea.Felis.2000',\n",
       " 'Ant-WAIS-Divide.Severinghaus.2012',\n",
       " 'Asi-SourthAndMiddleUrals.Demezhko.2007',\n",
       " 'Ocn-AlboranSea436B.Nieto-Moreno.2013',\n",
       " 'Eur-SpannagelCave.Mangini.2005',\n",
       " 'Ocn-FeniDrift.Richter.2009',\n",
       " 'Eur-LakeSilvaplana.Trachsel.2010',\n",
       " 'Ocn-PedradeLume-CapeVerdeIslands.Moses.2006',\n",
       " 'Ocn-SinaiPeninsula_RedSea.Moustafa.2000',\n",
       " 'Eur-NorthernSpain.Martin-Chivelet.2011',\n",
       " 'Arc-Kongressvatnet.D_Andrea.2012',\n",
       " 'Eur-CoastofPortugal.Abrantes.2011',\n",
       " 'Eur-SpanishPyrenees.Dorado-Linan.2012',\n",
       " 'Eur-FinnishLakelands.Helama.2014',\n",
       " 'Eur-NorthernScandinavia.Esper.2012',\n",
       " 'Eur-Stockholm.Leijonhufvud.2009']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.get_all_dataset_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38462639-4ea3-47cc-b815-408fd370516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "D2 = D.pop('Ocn-RedSea.Felis.2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d347bb19-72c8-4a3e-a714-5a3d6765e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 LiPD files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ocn-RedSea.Felis.2000', 'ODP846.Lawrence.2006']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2.load('../data/ODP846.Lawrence.2006.lpd')\n",
    "D2.get_all_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971321f-6910-430c-8ea6-7f902bf37ad5",
   "metadata": {},
   "source": [
    "Let's perform a similar query, but asking for the datasetID in addition to returning the dataset name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65b7f392-d969-48db-af07-0f0d10e761d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>dsname</th>\n",
       "      <th>datasetID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://linked.earth/lipd/Ocn-RedSea.Felis.2000</td>\n",
       "      <td>Ocn-RedSea.Felis.2000</td>\n",
       "      <td>4fZQAHmeuJn8ipLfurWv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ds                 dsname  \\\n",
       "0  http://linked.earth/lipd/Ocn-RedSea.Felis.2000  Ocn-RedSea.Felis.2000   \n",
       "\n",
       "              datasetID  \n",
       "0  4fZQAHmeuJn8ipLfurWv  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query =\"\"\"\n",
    "\n",
    "PREFIX le:<http://linked.earth/ontology#>\n",
    "\n",
    "SELECT ?ds ?dsname ?datasetID WHERE{\n",
    "\n",
    "?ds a le:Dataset .\n",
    "?ds le:name ?dsname .\n",
    "?ds le:datasetId ?datasetID}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "res, res_df = D2.query(query)\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4cb191-1451-4e3d-9728-2d6465f7ce78",
   "metadata": {},
   "source": [
    "As you can see, only the PAGES2k dataset was returned through this query. The ODP846 dataset was omitted because it doesn't have a datasetID. If you want to make this query optional, then all you need to do is write `OPTIONAL` in front of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bae7a33-5367-4887-93ef-f8032ed7a753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>dsname</th>\n",
       "      <th>datasetID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://linked.earth/lipd/Ocn-RedSea.Felis.2000</td>\n",
       "      <td>Ocn-RedSea.Felis.2000</td>\n",
       "      <td>4fZQAHmeuJn8ipLfurWv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://linked.earth/lipd/ODP846.Lawrence.2006</td>\n",
       "      <td>ODP846.Lawrence.2006</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ds                 dsname  \\\n",
       "0  http://linked.earth/lipd/Ocn-RedSea.Felis.2000  Ocn-RedSea.Felis.2000   \n",
       "1   http://linked.earth/lipd/ODP846.Lawrence.2006   ODP846.Lawrence.2006   \n",
       "\n",
       "              datasetID  \n",
       "0  4fZQAHmeuJn8ipLfurWv  \n",
       "1                  None  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query =\"\"\"\n",
    "\n",
    "PREFIX le:<http://linked.earth/ontology#>\n",
    "\n",
    "SELECT ?ds ?dsname ?datasetID WHERE{\n",
    "\n",
    "?ds a le:Dataset .\n",
    "?ds le:name ?dsname .\n",
    "OPTIONAL{?ds le:datasetId ?datasetID.}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "res, res_df = D2.query(query)\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf18b83-3f26-48df-9697-c5fd04e42f35",
   "metadata": {},
   "source": [
    "In this case, you at least get the dataset name. When to you use the `OPTIONAL` filtering is really up to you. If the answer associated with a specific property is critical to your analysis, then it allows you to filter out these datasets directly. However, if the piece of information is not critical, you may want to use the `OPTIONAL` filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6e74e-78af-487e-a93d-2169f2df6916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
